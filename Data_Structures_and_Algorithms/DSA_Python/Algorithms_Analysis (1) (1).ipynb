{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5ZnkxrOcdpe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdOeWrqVceXm"
      },
      "source": [
        "**Algorithm and Data Structure Analysis**\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "Algorithm and data structure analysis is a fundamental aspect of computer science and software engineering. It involves the study of algorithms' efficiency and performance characteristics, as well as the design and analysis of data structures for storing and organizing data effectively. This document provides an overview of algorithm and data structure analysis, including key concepts, techniques, and methodologies.\n",
        "\n",
        "**1. Algorithms**\n",
        "\n",
        "An algorithm is a step-by-step procedure for solving a problem or performing a task. It specifies a sequence of operations to be executed in order to achieve the desired outcome. Algorithm analysis involves evaluating an algorithm's efficiency in terms of time complexity, space complexity, and other relevant metrics.\n",
        "\n",
        "**1.1. Time Complexity**\n",
        "\n",
        "Time complexity measures the amount of computational time required by an algorithm to solve a problem as a function of the input size. Commonly used notations for expressing time complexity include Big O, Big Omega, and Big Theta.\n",
        "\n",
        "- Big O Notation (O): Represents the upper bound or worst-case scenario of an algorithm's time complexity.\n",
        "- Big Omega Notation (Ω): Represents the lower bound or best-case scenario of an algorithm's time complexity.\n",
        "- Big Theta Notation (Θ): Represents both the upper and lower bounds of an algorithm's time complexity, indicating tight asymptotic bounds.\n",
        "\n",
        "**1.2. Space Complexity**\n",
        "\n",
        "Space complexity measures the amount of memory space required by an algorithm to solve a problem as a function of the input size. It considers the amount of memory used by the algorithm for variables, data structures, and other resources.\n",
        "\n",
        "**1.3. Analysis Techniques**\n",
        "\n",
        "- **Asymptotic Analysis**: Evaluates the behavior of an algorithm as the input size approaches infinity.\n",
        "- **Worst-Case, Best-Case, and Average-Case Analysis**: Examines the performance of an algorithm under different input scenarios.\n",
        "- **Amortized Analysis**: Analyzes the average time or space complexity of a sequence of operations, rather than individual operations.\n",
        "\n",
        "**2. Data Structures**\n",
        "\n",
        "A data structure is a way of organizing and storing data to facilitate efficient access, modification, and retrieval operations. Different data structures are suited to different types of applications and usage scenarios.\n",
        "\n",
        "**2.1. Common Data Structures**\n",
        "\n",
        "- **Arrays**: Contiguous blocks of memory used to store elements of the same data type.\n",
        "- **Linked Lists**: Collections of nodes, where each node contains a data element and a reference to the next node in the sequence.\n",
        "- **Stacks**: Last In, First Out (LIFO) data structures that support push and pop operations.\n",
        "- **Queues**: First In, First Out (FIFO) data structures that support enqueue and dequeue operations.\n",
        "- **Trees**: Hierarchical data structures composed of nodes, where each node has a parent-child relationship.\n",
        "- **Graphs**: Non-linear data structures consisting of nodes and edges, used to represent relationships between entities.\n",
        "\n",
        "**2.2. Analysis of Data Structures**\n",
        "\n",
        "- **Time Complexity**: Analyzes the efficiency of operations (e.g., insertion, deletion, search) performed on a data structure.\n",
        "- **Space Complexity**: Analyzes the amount of memory required by a data structure to store its elements.\n",
        "\n",
        "**3. Algorithm Design Paradigms**\n",
        "\n",
        "Various algorithm design paradigms provide strategies for solving different types of problems efficiently.\n",
        "\n",
        "- **Divide and Conquer**: Breaks down a problem into smaller subproblems, solves each subproblem recursively, and combines the solutions to solve the original problem.\n",
        "- **Dynamic Programming**: Solves problems by breaking them down into simpler subproblems and storing the solutions to subproblems to avoid redundant computations.\n",
        "- **Greedy Algorithms**: Makes a series of locally optimal choices at each step with the hope of finding a global optimum solution.\n",
        "- **Backtracking**: Systematically explores all possible solutions to a problem by constructing candidates incrementally and abandoning a candidate as soon as it is determined to be infeasible.\n",
        "- **Branch and Bound**: Combines elements of backtracking and greedy algorithms to systematically explore the solution space, pruning branches that are unlikely to lead to an optimal solution.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "Algorithm and data structure analysis are essential for developing efficient and scalable software solutions. By understanding the performance characteristics of algorithms and the trade-offs associated with different data structures, developers can make informed design decisions and optimize their code for better performance. Continuous research and innovation in algorithm and data structure analysis play a crucial role in advancing the field of computer science and solving complex computational problems efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYMSWwCJfEHl"
      },
      "source": [
        "Sure, let's delve deeper into each of these analysis techniques:\n",
        "\n",
        "**1. Asymptotic Analysis:**\n",
        "\n",
        "Asymptotic analysis is a method used to evaluate the performance of an algorithm as the input size approaches infinity. It focuses on understanding how the algorithm's time or space complexity grows relative to the size of the input. This analysis is crucial because it provides insights into how the algorithm will perform when dealing with large datasets.\n",
        "\n",
        "The most common notation used in asymptotic analysis is Big O notation (O), which represents the upper bound or worst-case scenario of an algorithm's time complexity. It describes the maximum amount of time an algorithm will take to execute for any input size. For example, if an algorithm has a time complexity of O(n), it means that its execution time grows linearly with the size of the input.\n",
        "\n",
        "Other notations used in asymptotic analysis include Big Omega notation (Ω), representing the lower bound or best-case scenario, and Big Theta notation (Θ), representing both the upper and lower bounds of the algorithm's time complexity.\n",
        "\n",
        "Asymptotic analysis allows developers to compare algorithms and make informed decisions about which one to use based on their performance characteristics and scalability.\n",
        "\n",
        "**2. Worst-Case, Best-Case, and Average-Case Analysis:**\n",
        "\n",
        "Worst-case, best-case, and average-case analyses examine the performance of an algorithm under different input scenarios.\n",
        "\n",
        "- **Worst-case analysis**: This analysis considers the scenario where the algorithm takes the maximum amount of time or space to execute for any given input. It helps in identifying the upper bound on the algorithm's performance. For example, for a sorting algorithm, the worst-case scenario might be when the input array is in reverse order.\n",
        "\n",
        "- **Best-case analysis**: This analysis considers the scenario where the algorithm takes the minimum amount of time or space to execute for any given input. It provides insights into the lower bound on the algorithm's performance. However, the best-case scenario is often not very informative because it may not represent typical input data.\n",
        "\n",
        "- **Average-case analysis**: This analysis considers the expected performance of an algorithm over all possible inputs, usually assuming some probability distribution for the inputs. It provides a more realistic estimation of an algorithm's performance compared to worst-case or best-case scenarios. Average-case analysis is often used when the input data distribution is known or can be estimated.\n",
        "\n",
        "By analyzing an algorithm's performance under different scenarios, developers can gain a comprehensive understanding of its behavior and make appropriate design choices.\n",
        "\n",
        "**3. Amortized Analysis:**\n",
        "\n",
        "Amortized analysis is a method used to analyze the average time or space complexity of a sequence of operations performed by an algorithm, rather than focusing on individual operations. It is particularly useful for algorithms or data structures where the cost of certain operations varies over time but averages out to a more predictable value over the long run.\n",
        "\n",
        "One common example of amortized analysis is the analysis of dynamic array resizing operations. When the array reaches its capacity, it needs to be resized, which typically involves allocating a new array and copying elements from the old array to the new one. This operation can be expensive, but it doesn't occur after every insertion. Instead, it occurs occasionally as the array grows. Amortized analysis allows us to spread out the cost of resizing operations over multiple insertions, resulting in an average cost per insertion that is lower than the worst-case cost.\n",
        "\n",
        "Amortized analysis provides a more accurate picture of the overall performance of an algorithm or data structure over a sequence of operations, taking into account both expensive and inexpensive operations. It helps in making decisions about the suitability of an algorithm or data structure for a given problem domain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TAzbelBpWa-"
      },
      "source": [
        "Before delving deeper into the intricacies of algorithmic analysis and problem-solving techniques, it's essential to establish a solid understanding of fundamental data structures. These foundational structures serve as the backbone of computational systems, providing organized methods for storing, managing, and manipulating data. In the upcoming sections, we'll embark on an exploration of basic data structures, ranging from simple arrays and linked lists to more complex structures like stacks, queues, trees, and graphs. By comprehensively understanding these fundamental data structures, we equip ourselves with the essential tools necessary for efficient algorithm design, enabling us to tackle a wide array of computational challenges with confidence and precision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap2KL4IypgJ_"
      },
      "source": [
        "### **ARRAYS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcdMWoV7pngX"
      },
      "source": [
        "**1. Accessing an Element:**\n",
        "\n",
        "Accessing an element in an array by index is a constant-time operation, denoted as O(1). This is because arrays provide direct access to elements using their index. Regardless of the size of the array, accessing an element requires only a simple calculation to determine its memory location based on the index.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57m-x__ppi-s",
        "outputId": "5daf6625-2fb9-4f90-e97a-0a1f8cc78c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30\n"
          ]
        }
      ],
      "source": [
        "my_array = [10, 20, 30, 40, 50]\n",
        "print(my_array[2])  # Accessing element at index 2 (value: 30) - O(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtgA9Yszp5L2"
      },
      "source": [
        "**2. Insertion or Deletion at the End (Amortized):**\n",
        "\n",
        "Inserting or deleting an element at the end of an array typically involves O(1) time complexity on average, but it can occasionally require O(n) time complexity due to resizing the array when it reaches its capacity. However, such resizing operations are infrequent and are amortized over multiple insertions or deletions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "641Wc3z1pxyl",
        "outputId": "a2b0bddf-4c3e-42ba-d588-c324db702311"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_array = [10, 20, 30, 40, 50]\n",
        "my_array.append(60)  # Inserting element at the end - O(1) (amortized)\n",
        "my_array.pop()  # Deleting element from the end - O(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eMxHQcrqD4E"
      },
      "source": [
        "**3. Insertion or Deletion at an Arbitrary Position:**\n",
        "\n",
        "Inserting or deleting an element at an arbitrary position in an array generally requires shifting elements to accommodate the new element or fill the gap created by the deleted element. This operation has a time complexity of O(n), as it may involve moving a portion of the array elements.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64MySYg_qG9Z",
        "outputId": "fc37186c-fef4-402a-a08c-794c0d57dce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[10, 20, 25, 40, 50]\n"
          ]
        }
      ],
      "source": [
        "my_array = [10, 20, 30, 40, 50]\n",
        "my_array.insert(2, 25)  # Inserting element at index 2 - O(n)\n",
        "del my_array[3]  # Deleting element at index 3 - O(n)\n",
        "print(my_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F9h1KQoqGua"
      },
      "source": [
        "It's important to note that while arrays provide efficient random access to elements, their performance for insertion and deletion operations can degrade as the size of the array increases, especially when these operations are performed frequently or at arbitrary positions within the array. In such cases, alternative data structures like linked lists may offer better performance for dynamic data manipulation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL62qw2eqmDm"
      },
      "source": [
        "**1. Characteristics of Arrays:**\n",
        "\n",
        "Arrays are fundamental data structures that store elements of the same data type in contiguous memory locations. Some key characteristics of arrays include:\n",
        "\n",
        "- **Fixed Size:** Arrays have a fixed size determined at the time of their creation. Once allocated, the size of an array cannot be changed dynamically.\n",
        "\n",
        "- **Random Access:** Arrays allow for direct access to elements using an index. This allows for constant-time access to any element in the array.\n",
        "\n",
        "- **Sequential Storage:** Elements in an array are stored sequentially in memory, with each element occupying a fixed amount of memory space.\n",
        "\n",
        "- **Homogeneity:** Arrays can only store elements of the same data type. This homogeneity ensures efficient memory usage and allows for predictable access patterns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwMhtFntqyBG"
      },
      "source": [
        "**2. Operations and Complexity Analysis:**\n",
        "\n",
        "- **Accessing an Element:** Accessing an element in an array by its index is a constant-time operation, denoted as O(1). This is because the index of an element can be used to calculate its memory address directly.\n",
        "\n",
        "- **Insertion and Deletion:** Inserting or deleting an element at the end of an array (assuming no resizing is needed) takes constant time, O(1). However, inserting or deleting an element at an arbitrary position in the array requires shifting elements, resulting in O(n) time complexity, where n is the number of elements in the array.\n",
        "\n",
        "- **Search:** Searching for an element in an unsorted array requires sequential scanning, resulting in O(n) time complexity in the worst case. However, if the array is sorted, binary search can be applied, resulting in O(log n) time complexity.\n",
        "\n",
        "- **Traversal:** Traversing an array involves visiting each element sequentially. As there are n elements in the array, the time complexity of traversal is O(n).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBjTzuDyq0p1"
      },
      "source": [
        "**3. Applications:**\n",
        "\n",
        "Arrays are used in various applications, including:\n",
        "\n",
        "- **Data Storage:** Arrays are widely used for storing collections of data efficiently, such as lists of numbers, strings, or objects.\n",
        "\n",
        "- **Matrices and Multidimensional Data:** Arrays can represent matrices and multidimensional data structures, making them suitable for numerical computations and image processing.\n",
        "\n",
        "- **Dynamic Memory Allocation:** Arrays are used as a basis for implementing dynamic data structures such as stacks, queues, and hash tables, which dynamically allocate and manage memory as needed.\n",
        "\n",
        "- **Performance-Critical Applications:** Arrays are preferred in performance-critical applications where constant-time access and efficient memory usage are essential, such as in numerical simulations and real-time systems.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlwPuF44rQp5"
      },
      "source": [
        "## **LINKED LIST**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywtgZbKfrmEf"
      },
      "source": [
        "Linked lists are versatile data structures that offer flexibility in managing dynamic collections of data. Understanding their characteristics, operations, and complexities is essential for leveraging their utility in various computational tasks and applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4nV8-hbrZ4T"
      },
      "source": [
        "**1. Characteristics of Linked Lists:**\n",
        "\n",
        "Linked lists are linear data structures consisting of nodes, where each node contains a data element and a reference (pointer) to the next node in the sequence. Some key characteristics of linked lists include:\n",
        "\n",
        "- **Dynamic Size:** Linked lists can dynamically grow or shrink in size, as nodes can be added or removed without needing contiguous memory blocks.\n",
        "\n",
        "- **Dynamic Memory Allocation:** Nodes in a linked list are dynamically allocated from the heap, allowing for efficient memory usage and flexibility in managing memory.\n",
        "\n",
        "- **Sequential Storage:** Unlike arrays, linked list elements are not stored sequentially in memory. Instead, each node contains a reference to the next node, forming a chain-like structure.\n",
        "\n",
        "- **No Fixed Size:** Linked lists have no fixed size limitations, allowing them to accommodate any number of elements as needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PETZ3Kxlrd-4"
      },
      "source": [
        "**2. Operations and Complexity Analysis:**\n",
        "\n",
        "- **Accessing an Element:** Accessing an element in a linked list by its index requires traversing the list sequentially from the head node until reaching the desired position. Therefore, the time complexity of accessing an element is O(n), where n is the number of elements in the list.\n",
        "\n",
        "- **Insertion:** Inserting an element at the beginning of a linked list takes constant time, O(1), as it involves updating the head pointer to point to the new node. Inserting at an arbitrary position requires traversing the list to find the insertion point, resulting in O(n) time complexity.\n",
        "\n",
        "- **Deletion:** Deleting an element from a linked list also involves traversing the list to find the element to be deleted and updating the pointers to remove it from the list. Deleting an element at the beginning or end of the list takes constant time, O(1), while deleting at an arbitrary position requires O(n) time complexity.\n",
        "\n",
        "- **Search:** Searching for an element in a linked list requires traversing the list sequentially from the beginning to the end until the desired element is found or until the end of the list is reached. Therefore, the time complexity of searching for an element is O(n) in the worst case.\n",
        "\n",
        "- **Traversal:** Traversing a linked list involves visiting each node in the list sequentially from the head node to the last node. The time complexity of traversal is O(n), where n is the number of elements in the list.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKfFWEAep79V"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Node:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.next = None\n",
        "\n",
        "class SinglyLinkedList:\n",
        "    def __init__(self):\n",
        "        self.head = None\n",
        "\n",
        "    # Insertion at the beginning - O(1)\n",
        "    def insert_at_beginning(self, data):\n",
        "        new_node = Node(data)\n",
        "        new_node.next = self.head\n",
        "        self.head = new_node\n",
        "\n",
        "    # Insertion at the end - O(n)\n",
        "    def insert_at_end(self, data):\n",
        "        new_node = Node(data)\n",
        "        if not self.head:\n",
        "            self.head = new_node\n",
        "            return\n",
        "        current = self.head\n",
        "        while current.next:\n",
        "            current = current.next\n",
        "        current.next = new_node\n",
        "\n",
        "    # Deletion at the beginning - O(1)\n",
        "    def delete_at_beginning(self):\n",
        "        if not self.head:\n",
        "            print(\"List is empty\")\n",
        "            return\n",
        "        self.head = self.head.next\n",
        "\n",
        "    # Deletion at the end - O(n)\n",
        "    def delete_at_end(self):\n",
        "        if not self.head:\n",
        "            print(\"List is empty\")\n",
        "            return\n",
        "        if not self.head.next:\n",
        "            self.head = None\n",
        "            return\n",
        "        current = self.head\n",
        "        while current.next.next:\n",
        "            current = current.next\n",
        "        current.next = None\n",
        "\n",
        "    # Search - O(n)\n",
        "    def search(self, key):\n",
        "        current = self.head\n",
        "        while current:\n",
        "            if current.data == key:\n",
        "                return True\n",
        "            current = current.next\n",
        "        return False\n",
        "\n",
        "    # Traversal - O(n)\n",
        "    def display(self):\n",
        "        current = self.head\n",
        "        while current:\n",
        "            print(current.data, end=\" -> \")\n",
        "            current = current.next\n",
        "        print(\"None\")\n",
        "\n",
        "# Usage\n",
        "sll = SinglyLinkedList()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvSovOcF1GLZ"
      },
      "source": [
        "Explanation:\n",
        "\n",
        "- **Insertion at the beginning:** Involves creating a new node with the given data and updating the head pointer to point to this new node. Since this operation involves only a few pointer manipulations, it takes constant time, O(1).\n",
        "\n",
        "- **Insertion at the end:** Involves traversing the entire list to find the last node and then appending the new node after it. As the traversal takes linear time proportional to the number of nodes in the list, this operation takes O(n) time complexity.\n",
        "\n",
        "- **Deletion at the beginning:** Involves updating the head pointer to skip the first node, effectively removing it from the list. This operation takes constant time, O(1), as it involves only a few pointer manipulations.\n",
        "\n",
        "- **Deletion at the end:** Involves traversing the list to find the second-to-last node and then updating its next pointer to None. Since traversal takes linear time proportional to the number of nodes in the list, this operation takes O(n) time complexity.\n",
        "\n",
        "- **Search:** Involves traversing the entire list to find the node with the given key. As traversal takes linear time proportional to the number of nodes in the list, this operation takes O(n) time complexity in the worst case.\n",
        "\n",
        "- **Traversal:** Involves visiting each node in the list sequentially from the head to the last node and printing its data. Since traversal requires visiting each node once, it takes linear time proportional to the number of nodes in the list, resulting in O(n) time complexity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3j-Kmn-5rgr2"
      },
      "source": [
        "**3. Applications:**\n",
        "\n",
        "Linked lists are used in various applications, including:\n",
        "\n",
        "- **Dynamic Data Structures:** Linked lists serve as the foundation for implementing dynamic data structures such as stacks, queues, and hash tables, providing efficient insertion and deletion operations.\n",
        "\n",
        "- **Memory Management:** Linked lists are used in memory management systems for dynamic memory allocation, allowing for efficient allocation and deallocation of memory blocks.\n",
        "\n",
        "- **Text Processing:** Linked lists are used in text editors to represent text buffers, enabling efficient insertion, deletion, and manipulation of text.\n",
        "\n",
        "- **Operating Systems:** Linked lists are used in operating systems for managing system resources such as processes, files, and directories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZgfkDUc1mGR"
      },
      "source": [
        "## **3. STACKS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KU4mu5yp1uTf"
      },
      "source": [
        "**1. Characteristics of Stacks:**\n",
        "\n",
        "- Stacks follow the Last In, First Out (LIFO) principle, where the last element added to the stack is the first one to be removed.\n",
        "- They are linear data structures with two primary operations: push and pop.\n",
        "- Stacks can be implemented using various underlying data structures such as arrays, linked lists, or dynamic arrays.\n",
        "- They have a fixed size in some implementations, while others dynamically resize as needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7J0aH_m1x1D"
      },
      "source": [
        "**2. Operations and Complexity Analysis:**\n",
        "\n",
        "- **Push:** Adds an element to the top of the stack.\n",
        "  - Time Complexity: O(1) - Constant time, as it involves appending an element to the end of the stack.\n",
        "\n",
        "- **Pop:** Removes and returns the top element from the stack.\n",
        "  - Time Complexity: O(1) - Constant time, as it involves removing the last element from the stack.\n",
        "\n",
        "- **Peek (or Top):** Returns the top element of the stack without removing it.\n",
        "  - Time Complexity: O(1) - Constant time, as it only involves accessing the last element of the stack.\n",
        "\n",
        "- **IsEmpty:** Checks if the stack is empty.\n",
        "  - Time Complexity: O(1) - Constant time, as it only involves checking if the underlying data structure is empty.\n",
        "\n",
        "- **Size:** Returns the number of elements in the stack.\n",
        "  - Time Complexity: O(1) - Constant time, as it only involves retrieving the size of the underlying data structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLvGUE5v15Ns"
      },
      "outputs": [],
      "source": [
        "class Stack:\n",
        "    def __init__(self):\n",
        "        self.items = []\n",
        "\n",
        "    # Push operation - O(1)\n",
        "    def push(self, item):\n",
        "        self.items.append(item)\n",
        "\n",
        "    # Pop operation - O(1)\n",
        "    def pop(self):\n",
        "        if not self.is_empty():\n",
        "            return self.items.pop()\n",
        "        else:\n",
        "            print(\"Stack is empty\")\n",
        "            return None\n",
        "\n",
        "    # Peek operation - O(1)\n",
        "    def peek(self):\n",
        "        if not self.is_empty():\n",
        "            return self.items[-1]\n",
        "        else:\n",
        "            print(\"Stack is empty\")\n",
        "            return None\n",
        "\n",
        "    # IsEmpty operation - O(1)\n",
        "    def is_empty(self):\n",
        "        return len(self.items) == 0\n",
        "\n",
        "    # Size operation - O(1)\n",
        "    def size(self):\n",
        "        return len(self.items)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOr_O5Q12Gh_",
        "outputId": "4f1af236-d283-4905-d677-863bd3e98d80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stack: [1, 2, 3]\n",
            "Size: 3\n",
            "Peek: 3\n",
            "Stack after pop: [1, 2]\n"
          ]
        }
      ],
      "source": [
        "# Usage\n",
        "stack = Stack()\n",
        "stack.push(1)\n",
        "stack.push(2)\n",
        "stack.push(3)\n",
        "\n",
        "print(\"Stack:\", stack.items)  # Output: [1, 2, 3]\n",
        "print(\"Size:\", stack.size())   # Output: 3\n",
        "print(\"Peek:\", stack.peek())   # Output: 3\n",
        "\n",
        "stack.pop()\n",
        "print(\"Stack after pop:\", stack.items)  # Output: [1, 2]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zken9VSK10Rw"
      },
      "source": [
        "**3. Applications:**\n",
        "\n",
        "- Stacks are used in various applications such as expression evaluation, function call management, and backtracking algorithms.\n",
        "- They are employed in implementing algorithms like depth-first search (DFS) and in solving problems involving recursive function calls.\n",
        "- Stacks are used in undo mechanisms in applications like text editors and web browsers.\n",
        "- In programming languages, stacks are utilized for managing function call frames and local variables during program execution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6LO85c42m7r"
      },
      "source": [
        "## **4. QUEUES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qv8TQDH12s-2"
      },
      "source": [
        "**1. Characteristics of Queues:**\n",
        "\n",
        "- Queues follow the First In, First Out (FIFO) principle, where the first element added to the queue is the first one to be removed.\n",
        "- They are linear data structures with two primary operations: enqueue (add) and dequeue (remove).\n",
        "- Queues can be implemented using various underlying data structures such as arrays, linked lists, or dynamic arrays.\n",
        "- They can have a fixed size in some implementations, while others dynamically resize as needed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0Uh75832wyG"
      },
      "source": [
        "**2. Operations and Complexity Analysis:**\n",
        "\n",
        "- **Enqueue:** Adds an element to the rear (end) of the queue.\n",
        "  - Time Complexity: O(1) - Constant time, as it involves appending an element to the end of the queue.\n",
        "\n",
        "- **Dequeue:** Removes and returns the front (first) element from the queue.\n",
        "  - Time Complexity: O(1) - Constant time, as it involves removing the first element from the queue.\n",
        "\n",
        "- **Peek (or Front):** Returns the front element of the queue without removing it.\n",
        "  - Time Complexity: O(1) - Constant time, as it only involves accessing the first element of the queue.\n",
        "\n",
        "- **IsEmpty:** Checks if the queue is empty.\n",
        "  - Time Complexity: O(1) - Constant time, as it only involves checking if the underlying data structure is empty.\n",
        "\n",
        "- **Size:** Returns the number of elements in the queue.\n",
        "  - Time Complexity: O(1) - Constant time, as it only involves retrieving the size of the underlying data structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75K5lgyP1F13"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Queue:\n",
        "    def __init__(self):\n",
        "        self.items = []\n",
        "\n",
        "    # Enqueue operation - O(1)\n",
        "    def enqueue(self, item):\n",
        "        self.items.append(item)\n",
        "\n",
        "    # Dequeue operation - O(n)\n",
        "    def dequeue(self):\n",
        "        if not self.is_empty():\n",
        "            return self.items.pop(0)\n",
        "        else:\n",
        "            print(\"Queue is empty\")\n",
        "            return None\n",
        "\n",
        "    # Peek operation - O(1)\n",
        "    def peek(self):\n",
        "        if not self.is_empty():\n",
        "            return self.items[0]\n",
        "        else:\n",
        "            print(\"Queue is empty\")\n",
        "            return None\n",
        "\n",
        "    # IsEmpty operation - O(1)\n",
        "    def is_empty(self):\n",
        "        return len(self.items) == 0\n",
        "\n",
        "    # Size operation - O(1)\n",
        "    def size(self):\n",
        "        return len(self.items)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu1SG6Mg3BOU"
      },
      "source": [
        "Explanation:\n",
        "\n",
        "- **Initialization:** The constructor initializes an empty list to store the elements of the queue.\n",
        "- **Enqueue Operation:** The `enqueue` method appends an element to the end of the list, effectively adding it to the rear of the queue. Since list appending is a constant-time operation, the time complexity of `enqueue` is O(1).\n",
        "- **Dequeue Operation:** The `dequeue` method removes and returns the first element from the list if the queue is not empty. Since list popping from the beginning requires shifting elements, the time complexity of `dequeue` is O(n).\n",
        "- **Peek Operation:** The `peek` method returns the first element from the list without removing it, if the queue is not empty. It simply accesses the first element of the list, resulting in O(1) time complexity.\n",
        "- **IsEmpty Operation:** The `is_empty` method checks if the queue is empty by checking if the list is empty. This operation is also O(1) as it only involves a comparison.\n",
        "- **Size Operation:** The `size` method returns the number of elements in the queue by returning the length of the list. This operation is O(1) as it only involves retrieving the length of the list.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b44DMQoV2_vS",
        "outputId": "e7ce5cb9-26a4-454f-ba2d-b6e828bc82b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Queue: [1, 2, 3]\n",
            "Size: 3\n",
            "Peek: 1\n",
            "Queue after dequeue: [2, 3]\n"
          ]
        }
      ],
      "source": [
        "# Usage\n",
        "queue = Queue()\n",
        "queue.enqueue(1)\n",
        "queue.enqueue(2)\n",
        "queue.enqueue(3)\n",
        "\n",
        "print(\"Queue:\", queue.items)  # Output: [1, 2, 3]\n",
        "print(\"Size:\", queue.size())   # Output: 3\n",
        "print(\"Peek:\", queue.peek())   # Output: 1\n",
        "\n",
        "queue.dequeue()\n",
        "print(\"Queue after dequeue:\", queue.items)  # Output: [2, 3]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpCrblln2zZ9"
      },
      "source": [
        "**3. Applications:**\n",
        "\n",
        "- Queues are used in various applications such as job scheduling, process management, and breadth-first search (BFS) algorithms.\n",
        "- They are employed in scenarios requiring sequential processing, such as handling tasks in a computer system or managing requests in a network.\n",
        "- In operating systems, queues are used for managing input/output requests, process scheduling, and inter-process communication.\n",
        "- Queues play a crucial role in simulation and modeling, where they are used to represent waiting lines or buffers in systems such as traffic flow, manufacturing processes, and telecommunication networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85mFZqOM3VjW"
      },
      "source": [
        "## **5. TREES**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoWZpt323Xgu"
      },
      "source": [
        "**1. Characteristics of Trees:**\n",
        "\n",
        "- Trees are hierarchical data structures consisting of nodes connected by edges.\n",
        "- Each tree has a root node from which all other nodes are accessible.\n",
        "- Nodes in a tree are organized in a parent-child relationship, where each node (except the root) has exactly one parent and zero or more children.\n",
        "- Trees can have various types, including binary trees, binary search trees, balanced trees, and more.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ6FTjlL3biy"
      },
      "source": [
        "\n",
        "**2. Operations and Complexity Analysis:**\n",
        "\n",
        "- **Insertion:** Adding a new node to a tree.\n",
        "  - Time Complexity: O(log n) to O(n), depending on the type of tree. For balanced trees like AVL or Red-Black trees, insertion is typically O(log n), while for unbalanced trees, it can be O(n).\n",
        "\n",
        "- **Deletion:** Removing a node from a tree.\n",
        "  - Time Complexity: O(log n) to O(n), similar to insertion, depending on the type of tree and the deletion strategy used.\n",
        "\n",
        "- **Search:** Finding a specific node in a tree.\n",
        "  - Time Complexity: O(log n) to O(n), depending on the type of tree and whether it's balanced. In balanced trees, such as binary search trees (BST), search is typically O(log n) on average, but it can be O(n) in worst-case scenarios for unbalanced trees.\n",
        "\n",
        "- **Traversal:** Visiting all nodes of the tree in a specific order.\n",
        "  - Time Complexity: O(n), where n is the number of nodes in the tree. Traversal typically requires visiting each node exactly once.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoddSaTR45EJ"
      },
      "source": [
        "\n",
        "- **Insertion:** The insertion operation involves traversing the tree recursively from the root to the appropriate position for the new key. On average, this operation has a time complexity of O(log n) since it reduces the search space by half at each step. However, in the worst case (e.g., when the tree becomes unbalanced), insertion can take O(n) time complexity.\n",
        "\n",
        "- **Search:** Searching for a key in the BST also involves traversing the tree recursively from the root until finding the key or reaching a leaf node. Similar to insertion, the average time complexity of search is O(log n), but it can be O(n) in the worst case.\n",
        "\n",
        "- **In-order Traversal:** In-order traversal visits all nodes of the BST in sorted order. Since each node is visited exactly once, the time complexity of in-order traversal is O(n), where n is the number of nodes in the tree.\n",
        "\n",
        "These complexities reflect the average and worst-case scenarios for each operation, considering the tree is balanced. In practice, it's essential to ensure the tree remains balanced to maintain optimal performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkJUMe_N3G6o"
      },
      "outputs": [],
      "source": [
        "\n",
        "class TreeNode:\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "\n",
        "class BinarySearchTree:\n",
        "    def __init__(self):\n",
        "        self.root = None\n",
        "\n",
        "    # Insertion operation - O(log n) on average, O(n) in worst case\n",
        "    def insert(self, key):\n",
        "        self.root = self._insert_recursive(self.root, key)\n",
        "\n",
        "    def _insert_recursive(self, root, key):\n",
        "        if root is None:\n",
        "            return TreeNode(key)\n",
        "        if key < root.key:\n",
        "            root.left = self._insert_recursive(root.left, key)\n",
        "        elif key > root.key:\n",
        "            root.right = self._insert_recursive(root.right, key)\n",
        "        return root\n",
        "\n",
        "    # Search operation - O(log n) on average, O(n) in worst case\n",
        "    def search(self, key):\n",
        "        return self._search_recursive(self.root, key)\n",
        "\n",
        "    def _search_recursive(self, root, key):\n",
        "        if root is None or root.key == key:\n",
        "            return root\n",
        "        if key < root.key:\n",
        "            return self._search_recursive(root.left, key)\n",
        "        return self._search_recursive(root.right, key)\n",
        "\n",
        "    # In-order traversal - O(n)\n",
        "    def inorder_traversal(self):\n",
        "        result = []\n",
        "        self._inorder_traversal_recursive(self.root, result)\n",
        "        return result\n",
        "\n",
        "    def _inorder_traversal_recursive(self, root, result):\n",
        "        if root:\n",
        "            self._inorder_traversal_recursive(root.left, result)\n",
        "            result.append(root.key)\n",
        "            self._inorder_traversal_recursive(root.right, result)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6-Ikc1L3eW7"
      },
      "source": [
        "\n",
        "**3. Applications:**\n",
        "\n",
        "- **Binary Search Trees (BST):** Used for efficient searching, insertion, and deletion operations. Commonly employed in databases and in implementing associative arrays and sets.\n",
        "  \n",
        "- **Balanced Trees (AVL, Red-Black Trees):** Ensure balanced height, providing efficient operations even in the worst-case scenarios. Used in implementing data structures like sets and maps.\n",
        "\n",
        "- **Binary Trees:** Used in expression trees for representing mathematical expressions, decision trees in machine learning, and in hierarchical data storage structures like file systems.\n",
        "\n",
        "- **Trie (Prefix Tree):** Efficient for storing and retrieving strings, commonly used in dictionaries, autocomplete systems, and IP routing tables.\n",
        "\n",
        "- **Heap:** Implemented as a binary heap, used in priority queues and for efficient extraction of minimum or maximum elements.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKgay9mm5ZBJ"
      },
      "source": [
        "## **6. GRAPHS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBc-mS985UAe"
      },
      "source": [
        "Graphs are versatile data structures with numerous applications across various domains, including computer networking, social sciences, and recommendation systems. Understanding their characteristics, operations, and complexities is crucial for effectively utilizing them in different computational tasks and applications.\n",
        "\n",
        "**1. Characteristics of Graphs:**\n",
        "\n",
        "- Graphs are abstract data structures consisting of a set of vertices (nodes) and a set of edges connecting these vertices.\n",
        "- Graphs can be directed (edges have a specific direction) or undirected (edges have no direction).\n",
        "- Edges in a graph can be weighted or unweighted, representing different relationships between vertices.\n",
        "- Graphs can be cyclic (contain cycles) or acyclic (do not contain cycles).\n",
        "\n",
        "**2. Operations and Complexity Analysis:**\n",
        "\n",
        "- **Add Vertex:** Adds a new vertex to the graph.\n",
        "  - Time Complexity: O(1) - Constant time, as it involves adding a vertex to the vertex set.\n",
        "\n",
        "- **Add Edge:** Adds a new edge between two vertices.\n",
        "  - Time Complexity: O(1) - Constant time for unweighted graphs. For weighted graphs, it depends on the specific implementation.\n",
        "\n",
        "- **Remove Vertex:** Removes a vertex and all its associated edges from the graph.\n",
        "  - Time Complexity: O(|V| + |E|) - Linear time, where |V| is the number of vertices and |E| is the number of edges.\n",
        "\n",
        "- **Remove Edge:** Removes an edge between two vertices.\n",
        "  - Time Complexity: O(|E|) - Linear time, where |E| is the number of edges.\n",
        "\n",
        "- **Traversal (DFS, BFS):** Visits all vertices and edges of the graph.\n",
        "  - Time Complexity: O(|V| + |E|) - Linear time, where |V| is the number of vertices and |E| is the number of edges.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbvgYE2k5oLR",
        "outputId": "648d690f-722c-4669-b6e1-8dd81853d5b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Depth-First Traversal:\n",
            "1 2 4 3 \n",
            "Breadth-First Traversal:\n",
            "1 2 3 4 "
          ]
        }
      ],
      "source": [
        "\n",
        "class Graph:\n",
        "    def __init__(self):\n",
        "        self.graph = {}\n",
        "\n",
        "    # Add Vertex operation - O(1)\n",
        "    def add_vertex(self, vertex):\n",
        "        if vertex not in self.graph:\n",
        "            self.graph[vertex] = []\n",
        "\n",
        "    # Add Edge operation - O(1)\n",
        "    def add_edge(self, vertex1, vertex2):\n",
        "        if vertex1 in self.graph and vertex2 in self.graph:\n",
        "            self.graph[vertex1].append(vertex2)\n",
        "            self.graph[vertex2].append(vertex1)\n",
        "\n",
        "    # Remove Vertex operation - O(|V| + |E|)\n",
        "    def remove_vertex(self, vertex):\n",
        "        if vertex in self.graph:\n",
        "            del self.graph[vertex]\n",
        "            for v in self.graph:\n",
        "                if vertex in self.graph[v]:\n",
        "                    self.graph[v].remove(vertex)\n",
        "\n",
        "    # Remove Edge operation - O(|E|)\n",
        "    def remove_edge(self, vertex1, vertex2):\n",
        "        if vertex1 in self.graph and vertex2 in self.graph:\n",
        "            if vertex2 in self.graph[vertex1]:\n",
        "                self.graph[vertex1].remove(vertex2)\n",
        "            if vertex1 in self.graph[vertex2]:\n",
        "                self.graph[vertex2].remove(vertex1)\n",
        "\n",
        "    # Depth-First Traversal (DFS) - O(|V| + |E|)\n",
        "    def dfs(self, start, visited=None):\n",
        "        if visited is None:\n",
        "            visited = set()\n",
        "        visited.add(start)\n",
        "        print(start, end=' ')\n",
        "        for neighbor in self.graph[start]:\n",
        "            if neighbor not in visited:\n",
        "                self.dfs(neighbor, visited)\n",
        "\n",
        "    # Breadth-First Traversal (BFS) - O(|V| + |E|)\n",
        "    def bfs(self, start):\n",
        "        visited = set()\n",
        "        queue = [start]\n",
        "        visited.add(start)\n",
        "        while queue:\n",
        "            vertex = queue.pop(0)\n",
        "            print(vertex, end=' ')\n",
        "            for neighbor in self.graph[vertex]:\n",
        "                if neighbor not in visited:\n",
        "                    queue.append(neighbor)\n",
        "                    visited.add(neighbor)\n",
        "\n",
        "# Usage\n",
        "g = Graph()\n",
        "g.add_vertex(1)\n",
        "g.add_vertex(2)\n",
        "g.add_vertex(3)\n",
        "g.add_vertex(4)\n",
        "g.add_edge(1, 2)\n",
        "g.add_edge(1, 3)\n",
        "g.add_edge(2, 4)\n",
        "g.add_edge(3, 4)\n",
        "\n",
        "print(\"Depth-First Traversal:\")\n",
        "g.dfs(1)  # Output: 1 2 4 3\n",
        "\n",
        "print(\"\\nBreadth-First Traversal:\")\n",
        "g.bfs(1)  # Output: 1 2 3 4\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfmKi-Uq5gDl"
      },
      "source": [
        "**3. Applications:**\n",
        "\n",
        "- **Path Finding:** Finding the shortest path between two vertices in a graph, commonly used in navigation systems.\n",
        "  \n",
        "- **Network Routing:** Determining the best route for data packets to travel through a network, such as the internet.\n",
        "\n",
        "- **Social Networks:** Analyzing connections and relationships between individuals in social networks like Facebook or LinkedIn.\n",
        "\n",
        "- **Recommendation Systems:** Generating recommendations based on similarities between users or items in collaborative filtering systems.\n",
        "\n",
        "- **Graph Algorithms:** Various graph algorithms like Dijkstra's algorithm, Kruskal's algorithm, and Floyd-Warshall algorithm are used for solving optimization and shortest path problems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nV0Pg6SY44KN"
      },
      "source": [
        "**Path Finding**\n",
        "\n",
        "**Description**: Path finding involves finding the shortest path between two vertices in a graph. This is commonly used in navigation systems to provide users with the most efficient route from one location to another.\n",
        "\n",
        "**Example**: When you use GPS navigation on your smartphone to find the shortest route from your current location to a destination, path finding algorithms are employed behind the scenes to compute this route."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "def dijkstra(graph, start):\n",
        "    distances = {vertex: float('infinity') for vertex in graph}\n",
        "    distances[start] = 0\n",
        "    queue = [(0, start)]\n",
        "\n",
        "    while queue:\n",
        "        current_distance, current_vertex = heapq.heappop(queue)\n",
        "\n",
        "        if current_distance > distances[current_vertex]:\n",
        "            continue\n",
        "\n",
        "        for neighbor, weight in graph[current_vertex].items():\n",
        "            distance = current_distance + weight\n",
        "\n",
        "            if distance < distances[neighbor]:\n",
        "                distances[neighbor] = distance\n",
        "                heapq.heappush(queue, (distance, neighbor))\n",
        "\n",
        "    return distances\n",
        "\n",
        "# Example usage:\n",
        "graph = {\n",
        "    'A': {'B': 1, 'C': 4},\n",
        "    'B': {'A': 1, 'C': 2, 'D': 5},\n",
        "    'C': {'A': 4, 'B': 2, 'D': 1},\n",
        "    'D': {'B': 5, 'C': 1}\n",
        "}\n",
        "start_vertex = 'A'\n",
        "shortest_distances = dijkstra(graph, start_vertex)\n",
        "print(\"Shortest distances from vertex\", start_vertex, \":\", shortest_distances)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvgq5yGokhA8",
        "outputId": "41cd37ab-aa87-4c95-bceb-701254fb9722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shortest distances from vertex A : {'A': 0, 'B': 1, 'C': 3, 'D': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Network Routing (Shortest Path Problem):**\n",
        "\n",
        "**Description:** Network routing involves determining the best route for data packets to travel through a network, such as the internet. It ensures efficient and reliable data transmission by selecting optimal paths.\n",
        "\n",
        "**Example:** Internet routers use routing algorithms to forward data packets along the most efficient paths from the source to the destination based on factors like network congestion, latency, and reliability.\n",
        "\n",
        "**This can use the same implementation of Dijkstra's algorithm as above.**"
      ],
      "metadata": {
        "id": "icTrpDOhk_DK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Social Networks (Analyzing Connections):**\n",
        "\n",
        "**Description:** Social networks like Facebook or LinkedIn utilize algorithms to analyze connections and relationships between individuals. These algorithms help in understanding network structures, identifying influential users, and recommending connections or content.\n",
        "\n",
        "**Example:** Facebook's friend suggestion feature uses algorithms to analyze mutual connections, common interests, and interactions to suggest potential friends to users.\n",
        "\n",
        "For simplicity, let's consider a basic example of finding mutual friends between two users in a social network represented as a graph."
      ],
      "metadata": {
        "id": "MLu6zLhblMDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mutual_friends(graph, user1, user2):\n",
        "    if user1 not in graph or user2 not in graph:\n",
        "        return \"User not found in the network\"\n",
        "\n",
        "    user1_friends = set(graph[user1])\n",
        "    user2_friends = set(graph[user2])\n",
        "    mutual_friends = user1_friends.intersection(user2_friends)\n",
        "\n",
        "    return mutual_friends\n",
        "\n",
        "# Example usage:\n",
        "social_network = {\n",
        "    'Alice': ['Bob', 'Charlie', 'David'],\n",
        "    'Bob': ['Alice', 'Charlie'],\n",
        "    'Charlie': ['Alice', 'Bob', 'David'],\n",
        "    'David': ['Alice', 'Charlie']\n",
        "}\n",
        "user1 = 'Alice'\n",
        "user2 = 'Charlie'\n",
        "print(\"Mutual friends between\", user1, \"and\", user2, \":\", mutual_friends(social_network, user1, user2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCtaGW0ekz3D",
        "outputId": "7f71b7f0-fac4-4b2a-f18e-5424cca00708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mutual friends between Alice and Charlie : {'Bob', 'David'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recommendation Systems:**\n",
        "\n",
        "**Description:** Recommendation systems generate personalized recommendations for users based on their preferences, behaviors, and similarities with other users or items. These systems are widely used in e-commerce, streaming platforms, and content websites.\n",
        "\n",
        "**Example:** Netflix recommends movies or TV shows to users based on their viewing history, ratings, and similarities with other users who have similar tastes.\n",
        "\n",
        "For simplicity, let's consider a basic example of recommending items based on user-item ratings."
      ],
      "metadata": {
        "id": "dzIdKWUCmEYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_items(user_ratings, user, num_recommendations):\n",
        "    if user not in user_ratings:\n",
        "        return \"User not found\"\n",
        "\n",
        "    recommendations = []\n",
        "    user_ratings_sorted = sorted(user_ratings[user].items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    for item, rating in user_ratings_sorted:\n",
        "        if len(recommendations) == num_recommendations:\n",
        "            break\n",
        "        if item not in user_ratings[user]:\n",
        "            recommendations.append(item)\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# Example usage:\n",
        "user_item_ratings = {\n",
        "    'User1': {'Item1': 4, 'Item2': 5, 'Item3': 3},\n",
        "    'User2': {'Item1': 3, 'Item4': 4, 'Item5': 5},\n",
        "    'User3': {'Item2': 5, 'Item3': 4, 'Item6': 3}\n",
        "}\n",
        "user = 'User1'\n",
        "num_recommendations = 2\n",
        "print(\"Recommendations for\", user, \":\", recommend_items(user_item_ratings, user, num_recommendations))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNIdCFLLmRoa",
        "outputId": "f418eed7-8115-4866-de0e-7e4947ccae05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommendations for User1 : []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph Algorithms:**\n",
        "\n",
        "**Description:** Various graph algorithms such as Dijkstra's algorithm, Kruskal's algorithm, and Floyd-Warshall algorithm are used for solving optimization and shortest path problems on graphs. These algorithms find applications in transportation, logistics, network design, and resource allocation.\n",
        "\n",
        "**Example:** Dijkstra's algorithm is used by transportation companies to optimize delivery routes, while Kruskal's algorithm is employed in spanning tree construction for network design.\n",
        "\n",
        "Below implementations demonstrate the usage of Dijkstra's algorithm, Kruskal's algorithm, and Floyd-Warshall algorithm for solving various graph-related problems such as finding shortest paths, constructing minimum spanning trees, and finding all pair shortest paths."
      ],
      "metadata": {
        "id": "6b7dnllrmdBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph Algorithms:**\n",
        "\n",
        "**Dijkstra's Algorithm:**"
      ],
      "metadata": {
        "id": "0yZ0DsQcnHrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "def dijkstra(graph, start):\n",
        "    distances = {vertex: float('infinity') for vertex in graph}\n",
        "    distances[start] = 0\n",
        "    queue = [(0, start)]\n",
        "\n",
        "    while queue:\n",
        "        current_distance, current_vertex = heapq.heappop(queue)\n",
        "\n",
        "        if current_distance > distances[current_vertex]:\n",
        "            continue\n",
        "\n",
        "        for neighbor, weight in graph[current_vertex].items():\n",
        "            distance = current_distance + weight\n",
        "\n",
        "            if distance < distances[neighbor]:\n",
        "                distances[neighbor] = distance\n",
        "                heapq.heappush(queue, (distance, neighbor))\n",
        "\n",
        "    return distances\n",
        "\n",
        "# Example usage:\n",
        "graph = {\n",
        "    'A': {'B': 1, 'C': 4},\n",
        "    'B': {'A': 1, 'C': 2, 'D': 5},\n",
        "    'C': {'A': 4, 'B': 2, 'D': 1},\n",
        "    'D': {'B': 5, 'C': 1}\n",
        "}\n",
        "start_vertex = 'A'\n",
        "shortest_distances = dijkstra(graph, start_vertex)\n",
        "print(\"Shortest distances from vertex\", start_vertex, \":\", shortest_distances)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BU9XPLJnYo0",
        "outputId": "31c6ed74-b936-470f-b557-86a9af4a59c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shortest distances from vertex A : {'A': 0, 'B': 1, 'C': 3, 'D': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Kruskal's Algorithm:**"
      ],
      "metadata": {
        "id": "xyutlcXIndAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DisjointSet:\n",
        "    def __init__(self):\n",
        "        self.parent = {}\n",
        "\n",
        "    def find(self, vertex):\n",
        "        if vertex not in self.parent:\n",
        "            return vertex\n",
        "        if self.parent[vertex] != vertex:\n",
        "            self.parent[vertex] = self.find(self.parent[vertex])\n",
        "        return self.parent[vertex]\n",
        "\n",
        "    def union(self, vertex1, vertex2):\n",
        "        parent1 = self.find(vertex1)\n",
        "        parent2 = self.find(vertex2)\n",
        "        if parent1 != parent2:\n",
        "            self.parent[parent1] = parent2\n",
        "\n",
        "def kruskal(graph):\n",
        "    mst = []\n",
        "    disjoint_set = DisjointSet()\n",
        "    edges = [(weight, u, v) for u in graph for v, weight in graph[u].items()]\n",
        "    edges.sort()\n",
        "\n",
        "    for weight, u, v in edges:\n",
        "        if disjoint_set.find(u) != disjoint_set.find(v):\n",
        "            mst.append((u, v, weight))\n",
        "            disjoint_set.union(u, v)\n",
        "\n",
        "    return mst\n",
        "\n",
        "# Example usage:\n",
        "graph = {\n",
        "    'A': {'B': 1, 'C': 4},\n",
        "    'B': {'A': 1, 'C': 2, 'D': 5},\n",
        "    'C': {'A': 4, 'B': 2, 'D': 1},\n",
        "    'D': {'B': 5, 'C': 1}\n",
        "}\n",
        "minimum_spanning_tree = kruskal(graph)\n",
        "print(\"Minimum Spanning Tree (Kruskal's Algorithm):\", minimum_spanning_tree)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7tDCp1TncY5",
        "outputId": "ee11908d-ce63-44d4-b77e-2aabd74e877a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum Spanning Tree (Kruskal's Algorithm): [('A', 'B', 1), ('C', 'D', 1), ('B', 'C', 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Floyd-Warshall Algorithm:**"
      ],
      "metadata": {
        "id": "GooPX0FDnirQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def floyd_warshall(graph):\n",
        "    distances = {vertex: {v: float('infinity') for v in graph} for vertex in graph}\n",
        "\n",
        "    for vertex in graph:\n",
        "        distances[vertex][vertex] = 0\n",
        "\n",
        "    for u in graph:\n",
        "        for v in graph[u]:\n",
        "            distances[u][v] = graph[u][v]\n",
        "\n",
        "    for k in graph:\n",
        "        for i in graph:\n",
        "            for j in graph:\n",
        "                distances[i][j] = min(distances[i][j], distances[i][k] + distances[k][j])\n",
        "\n",
        "    return distances\n",
        "\n",
        "# Example usage:\n",
        "graph = {\n",
        "    'A': {'B': 1, 'C': 4},\n",
        "    'B': {'A': 1, 'C': 2, 'D': 5},\n",
        "    'C': {'A': 4, 'B': 2, 'D': 1},\n",
        "    'D': {'B': 5, 'C': 1}\n",
        "}\n",
        "all_pair_shortest_paths = floyd_warshall(graph)\n",
        "print(\"All Pair Shortest Paths (Floyd-Warshall Algorithm):\\n\", all_pair_shortest_paths)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJTHZ7xVnlE5",
        "outputId": "e2da8966-a9e2-453e-918f-53774d572a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Pair Shortest Paths (Floyd-Warshall Algorithm):\n",
            " {'A': {'A': 0, 'B': 1, 'C': 3, 'D': 4}, 'B': {'A': 1, 'B': 0, 'C': 2, 'D': 3}, 'C': {'A': 3, 'B': 2, 'C': 0, 'D': 1}, 'D': {'A': 4, 'B': 3, 'C': 1, 'D': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's understand some additional commonly used data structures or algorithms.\n",
        "\n",
        "**Hash Tables:**\n",
        "\n",
        "**Explanation:** Hash tables are data structures that store key-value pairs, allowing for efficient insertion, deletion, and lookup operations. They achieve this efficiency by using a hash function to map keys to indices in an array.\n",
        "\n",
        "**Code Implementation:**"
      ],
      "metadata": {
        "id": "TtQeLei0l-9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HashTable:\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "        self.table = [None] * size\n",
        "\n",
        "    def _hash(self, key):\n",
        "        return hash(key) % self.size\n",
        "\n",
        "    def insert(self, key, value):\n",
        "        index = self._hash(key)\n",
        "        self.table[index] = value\n",
        "\n",
        "    def search(self, key):\n",
        "        index = self._hash(key)\n",
        "        return self.table[index]\n",
        "\n",
        "# Example usage:\n",
        "hash_table = HashTable(10)\n",
        "hash_table.insert('apple', 10)\n",
        "hash_table.insert('banana', 20)\n",
        "print(hash_table.search('apple'))  # Output: 10\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FILUAkpwqwBo",
        "outputId": "91645dca-5526-4b4d-9ca9-94b8b472fba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sorting Algorithms:**\n",
        "\n",
        "**Explanation:** Sorting algorithms rearrange a list of elements in a specified order (e.g., ascending or descending). Various algorithms like merge sort, quick sort, heap sort, etc., achieve this task with different time and space complexities.\n",
        "\n",
        "**Code Implementation:**"
      ],
      "metadata": {
        "id": "nHx8GsHjq0p7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_sort(arr):\n",
        "    if len(arr) <= 1:\n",
        "        return arr\n",
        "    mid = len(arr) // 2\n",
        "    left = merge_sort(arr[:mid])\n",
        "    right = merge_sort(arr[mid:])\n",
        "    return merge(left, right)\n",
        "\n",
        "def merge(left, right):\n",
        "    result = []\n",
        "    i = j = 0\n",
        "    while i < len(left) and j < len(right):\n",
        "        if left[i] < right[j]:\n",
        "            result.append(left[i])\n",
        "            i += 1\n",
        "        else:\n",
        "            result.append(right[j])\n",
        "            j += 1\n",
        "    result.extend(left[i:])\n",
        "    result.extend(right[j:])\n",
        "    return result\n",
        "\n",
        "# Example usage:\n",
        "arr = [5, 2, 8, 1, 3]\n",
        "sorted_arr = merge_sort(arr)\n",
        "print(sorted_arr)  # Output: [1, 2, 3, 5, 8]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYeI4AgwrEdC",
        "outputId": "640de725-6827-4d73-bca3-6246c08817f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3, 5, 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Searching Algorithms:**\n",
        "\n",
        "**Explanation:** Searching algorithms locate a target value within a collection of elements. Common algorithms include linear search and binary search.\n",
        "\n",
        "**Code Implementation:**"
      ],
      "metadata": {
        "id": "3p2fWsltrHIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_search(arr, target):\n",
        "    left, right = 0, len(arr) - 1\n",
        "    while left <= right:\n",
        "        mid = left + (right - left) // 2\n",
        "        if arr[mid] == target:\n",
        "            return mid\n",
        "        elif arr[mid] < target:\n",
        "            left = mid + 1\n",
        "        else:\n",
        "            right = mid - 1\n",
        "    return -1\n",
        "\n",
        "# Example usage:\n",
        "arr = [1, 3, 5, 7, 9]\n",
        "target = 5\n",
        "index = binary_search(arr, target)\n",
        "print(index)  # Output: 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5pVgsdfrNxK",
        "outputId": "19296486-4065-4c13-c5f8-fe628ce50d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dynamic Programming:**\n",
        "\n",
        "**Explanation:** Dynamic programming is an algorithmic technique used to solve optimization problems by breaking them down into simpler subproblems and storing their solutions to avoid redundant computations.\n",
        "\n",
        "**Code Implementation:**"
      ],
      "metadata": {
        "id": "fx8RbBJMrDZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fibonacci(n):\n",
        "    if n <= 1:\n",
        "        return n\n",
        "    fib = [0] * (n + 1)\n",
        "    fib[1] = 1\n",
        "    for i in range(2, n + 1):\n",
        "        fib[i] = fib[i - 1] + fib[i - 2]\n",
        "    return fib[n]\n",
        "\n",
        "# Example usage:\n",
        "n = 5\n",
        "print(fibonacci(n))  # Output: 5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77epAtQZrb5d",
        "outputId": "0c41d832-e36f-47ec-be5b-57e4c889e226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Greedy Algorithms:**\n",
        "\n",
        "**Explanation:** Greedy algorithms make locally optimal choices at each step with the hope of finding a global optimum solution. They are often used for optimization problems where finding the exact solution is computationally expensive.\n",
        "\n",
        "**Code Implementation:**"
      ],
      "metadata": {
        "id": "VMC5pCbYmQLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def coin_change(coins, amount):\n",
        "    coins.sort(reverse=True)\n",
        "    num_coins = 0\n",
        "    for coin in coins:\n",
        "        while amount >= coin:\n",
        "            num_coins += 1\n",
        "            amount -= coin\n",
        "    if amount == 0:\n",
        "        return num_coins\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "# Example usage:\n",
        "coins = [1, 2, 5]\n",
        "amount = 11\n",
        "min_coins = coin_change(coins, amount)\n",
        "print(min_coins)  # Output: 3 (using 5, 5, 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeUatvkzrtuL",
        "outputId": "4fecc643-2eea-4d5e-a013-6d1e70258a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advanced Data Structures:**\n",
        "\n",
        "**Explanation:** Advanced data structures provide efficient solutions to specific problems or enable efficient operations on data. Priority queues, disjoint-set data structures (union-find), and trie structures are examples of advanced data structures.\n",
        "\n",
        "**Code Implementations:**\n",
        "\n",
        "**Priority Queue:**"
      ],
      "metadata": {
        "id": "_LjS5Y1SsAz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "class PriorityQueue:\n",
        "    def __init__(self):\n",
        "        self._queue = []\n",
        "        self._index = 0\n",
        "\n",
        "    def push(self, item, priority):\n",
        "        heapq.heappush(self._queue, (-priority, self._index, item))\n",
        "        self._index += 1\n",
        "\n",
        "    def pop(self):\n",
        "        return heapq.heappop(self._queue)[-1]\n",
        "\n",
        "# Example usage:\n",
        "pq = PriorityQueue()\n",
        "pq.push('task1', 5)\n",
        "pq.push('task2', 1)\n",
        "pq.push('task3', 3)\n",
        "print(pq.pop())  # Output: task1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joW3-9far_-6",
        "outputId": "d5316d82-2fcd-464e-a2d2-db5790836349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "task1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Disjoint-Set (Union-Find):**"
      ],
      "metadata": {
        "id": "4gFBtkTHs9Bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DisjointSet:\n",
        "    def __init__(self, n):\n",
        "        self.parent = list(range(n))\n",
        "        self.rank = [0] * n\n",
        "\n",
        "    def find(self, u):\n",
        "        if self.parent[u] != u:\n",
        "            self.parent[u] = self.find(self.parent[u])\n",
        "        return self.parent[u]\n",
        "\n",
        "    def union(self, u, v):\n",
        "        pu, pv = self.find(u), self.find(v)\n",
        "        if pu != pv:\n",
        "            if self.rank[pu] < self.rank[pv]:\n",
        "                self.parent[pu] = pv\n",
        "            elif self.rank[pu] > self.rank[pv]:\n",
        "                self.parent[pv] = pu\n",
        "            else:\n",
        "                self.parent[pv] = pu\n",
        "                self.rank[pu] += 1\n",
        "\n",
        "# Example usage:\n",
        "ds = DisjointSet(5)\n",
        "ds.union(0, 1)\n",
        "ds.union(2, 3)\n",
        "print(ds.find(1))  # Output: 0\n",
        "print(ds.find(3))  # Output: 2\n"
      ],
      "metadata": {
        "id": "s_f8LrCXtBH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trie Structure:**"
      ],
      "metadata": {
        "id": "OxPOm-s1tEZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrieNode:\n",
        "    def __init__(self):\n",
        "        self.children = {}\n",
        "        self.is_end_of_word = False\n",
        "\n",
        "class Trie:\n",
        "    def __init__(self):\n",
        "        self.root = TrieNode()\n",
        "\n",
        "    def insert(self, word):\n",
        "        node = self.root\n",
        "        for char in word:\n",
        "            if char not in node.children:\n",
        "                node.children[char] = TrieNode()\n",
        "            node = node.children[char]\n",
        "        node.is_end_of_word = True\n",
        "\n",
        "    def search(self, word):\n",
        "        node = self.root\n",
        "        for char in word:\n",
        "            if char not in node.children:\n",
        "                return False\n",
        "            node = node.children[char]\n",
        "        return node.is_end_of_word\n",
        "\n",
        "# Example usage:\n",
        "trie = Trie()\n",
        "words = [\"apple\", \"banana\", \"orange\"]\n",
        "for word in words:\n",
        "    trie.insert(word)\n",
        "print(trie.search(\"apple\"))  # Output: True\n",
        "print(trie.search(\"grape\"))  # Output: False\n"
      ],
      "metadata": {
        "id": "Jb0EOmxCtHzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**String Algorithms:**\n",
        "\n",
        "**Explanation:** String algorithms involve manipulating and processing strings efficiently. Common string algorithms include string matching algorithms (e.g., Knuth-Morris-Pratt algorithm, Rabin-Karp algorithm) and string processing techniques (e.g., string hashing, suffix arrays).\n",
        "\n",
        "**Code Implementations:**\n",
        "\n",
        "**Knuth-Morris-Pratt Algorithm (KMP):**"
      ],
      "metadata": {
        "id": "-h9ae28btL-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kmp_search(text, pattern):\n",
        "    prefix = compute_prefix(pattern)\n",
        "    j = 0\n",
        "    for i in range(len(text)):\n",
        "        while j > 0 and text[i] != pattern[j]:\n",
        "            j = prefix[j - 1]\n",
        "        if text[i] == pattern[j]:\n",
        "            j += 1\n",
        "        if j == len(pattern):\n",
        "            return i - j + 1\n",
        "    return -1\n",
        "\n",
        "def compute_prefix(pattern):\n",
        "    prefix = [0] * len(pattern)\n",
        "    j = 0\n",
        "    for i in range(1, len(pattern)):\n",
        "        while j > 0 and pattern[i] != pattern[j]:\n",
        "            j = prefix[j - 1]\n",
        "        if pattern[i] == pattern[j]:\n",
        "            j += 1\n",
        "        prefix[i] = j\n",
        "    return prefix\n",
        "\n",
        "# Example usage:\n",
        "text = \"ABABDABACDABABCABAB\"\n",
        "pattern = \"ABABCABAB\"\n",
        "print(kmp_search(text, pattern))  # Output: 10\n"
      ],
      "metadata": {
        "id": "G87HyAXitUxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Rabin-Karp Algorithm:**"
      ],
      "metadata": {
        "id": "cLBt8LNMtXI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rabin_karp_search(text, pattern, prime):\n",
        "    n, m = len(text), len(pattern)\n",
        "    if n < m:\n",
        "        return -1\n",
        "\n",
        "    pattern_hash = calculate_hash(pattern, prime)\n",
        "    text_hash = calculate_hash(text[:m], prime)\n",
        "\n",
        "    for i in range(n - m + 1):\n",
        "        if text_hash == pattern_hash and text[i:i + m] == pattern:\n",
        "            return i\n",
        "        if i < n - m:\n",
        "            text_hash = recalculate_hash(text, i, i + m, text_hash, m, prime)\n",
        "\n",
        "    return -1\n",
        "\n",
        "def calculate_hash(s, prime):\n",
        "    hash_value = 0\n",
        "    for char in s:\n",
        "        hash_value = (hash_value * 256 + ord(char)) % prime\n",
        "    return hash_value\n",
        "\n",
        "def recalculate_hash(text, old_index, new_index, old_hash, pattern_len, prime):\n",
        "    new_hash = (old_hash - ord(text[old_index]) * pow(256, pattern_len - 1)) % prime\n",
        "    new_hash = (new_hash * 256 + ord(text[new_index])) % prime\n",
        "    return new_hash\n",
        "\n",
        "# Example usage:\n",
        "text = \"ABABDABACDABABCABAB\"\n",
        "pattern = \"ABABCABAB\"\n",
        "prime = 101  # Choose a prime number\n",
        "print(rabin_karp_search(text, pattern, prime))  # Output: 10\n"
      ],
      "metadata": {
        "id": "M3fBuHuBtbH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph Algorithms (Advanced):**\n",
        "\n",
        "**Explanation:** Advanced graph algorithms delve deeper into optimization problems and graph theory concepts. Topics include minimum spanning trees, network flows, topological sorting, and graph coloring.\n",
        "\n",
        "**Code Implementations:**\n",
        "\n",
        "**Minimum Spanning Tree (Prim's Algorithm):**"
      ],
      "metadata": {
        "id": "g-ry0CpOteqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "def prim_mst(graph):\n",
        "    mst = []\n",
        "    visited = set()\n",
        "    start_node = list(graph.keys())[0]\n",
        "    heap = [(0, start_node)]\n",
        "\n",
        "    while heap:\n",
        "        weight, node = heapq.heappop(heap)\n",
        "        if node not in visited:\n",
        "            visited.add(node)\n",
        "            mst.append((weight, node))\n",
        "            for neighbor, weight in graph[node].items():\n",
        "                if neighbor not in visited:\n",
        "                    heapq.heappush(heap, (weight, neighbor))\n",
        "\n",
        "    return mst\n",
        "\n",
        "# Example usage:\n",
        "graph = {\n",
        "    'A': {'B': 1, 'C': 4},\n",
        "    'B': {'A': 1, 'C': 2, 'D': 5},\n",
        "    'C': {'A': 4, 'B': 2, 'D': 1},\n",
        "    'D': {'B': 5, 'C': 1}\n",
        "}\n",
        "minimum_spanning_tree = prim_mst(graph)\n",
        "print(\"Minimum Spanning Tree (Prim's Algorithm):\", minimum_spanning_tree)\n"
      ],
      "metadata": {
        "id": "ccdf7_W_tlGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Network Flows (Ford-Fulkerson Algorithm with Edmonds-Karp Implementation):**"
      ],
      "metadata": {
        "id": "YZHwqTCduKND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict, deque\n",
        "\n",
        "def edmonds_karp(graph, source, sink):\n",
        "    def bfs(graph, source, sink, parent):\n",
        "        visited = set()\n",
        "        queue = deque([source])\n",
        "        visited.add(source)\n",
        "        while queue:\n",
        "            u = queue.popleft()\n",
        "            for v, capacity in graph[u].items():\n",
        "                if v not in visited and capacity > 0:\n",
        "                    queue.append(v)\n",
        "                    visited.add(v)\n",
        "                    parent[v] = u\n",
        "        return True if sink in visited else False\n",
        "\n",
        "    max_flow = 0\n",
        "    parent = {}\n",
        "    while bfs(graph, source, sink, parent):\n",
        "        path_flow = float('inf')\n",
        "        s = sink\n",
        "        while s != source:\n",
        "            path_flow = min(path_flow, graph[parent[s]][s])\n",
        "            s = parent[s]\n",
        "        max_flow += path_flow\n",
        "        v = sink\n",
        "        while v != source:\n",
        "            u = parent[v]\n",
        "            graph[u][v] -= path_flow\n",
        "            graph[v][u] += path_flow\n",
        "            v = parent[v]\n",
        "    return max_flow\n",
        "\n",
        "# Example usage:\n",
        "graph = {\n",
        "    's': {'A': 10, 'B': 5},\n",
        "    'A': {'B': 15, 't': 10},\n",
        "    'B': {'C': 10, 't': 10},\n",
        "    'C': {'A': 5, 't': 10}\n",
        "}\n",
        "source = 's'\n",
        "sink = 't'\n",
        "max_flow = edmonds_karp(graph, source, sink)\n",
        "print(\"Maximum Flow from\", source, \"to\", sink, \":\", max_flow)\n"
      ],
      "metadata": {
        "id": "AmU_PfofuNnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topological Sorting (DFS):**"
      ],
      "metadata": {
        "id": "2X4UWffAuPIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def topological_sort(graph):\n",
        "    visited = set()\n",
        "    stack = []\n",
        "\n",
        "    def dfs(node):\n",
        "        visited.add(node)\n",
        "        for neighbor in graph[node]:\n",
        "            if neighbor not in visited:\n",
        "                dfs(neighbor)\n",
        "        stack.append(node)\n",
        "\n",
        "    for node in graph:\n",
        "        if node not in visited:\n",
        "            dfs(node)\n",
        "\n",
        "    return stack[::-1]\n",
        "\n",
        "# Example usage:\n",
        "graph = {\n",
        "    'A': ['B', 'C'],\n",
        "    'B': ['D'],\n",
        "    'C': ['D'],\n",
        "    'D': []\n",
        "}\n",
        "topological_order = topological_sort(graph)\n",
        "print(\"Topological Order:\", topological_order)\n"
      ],
      "metadata": {
        "id": "QUSdmoxLuSPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Graph Coloring (Backtracking):**"
      ],
      "metadata": {
        "id": "YtpT6PUfuT-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_safe(graph, node, color, color_map):\n",
        "    for neighbor in graph[node]:\n",
        "        if color_map[neighbor] == color:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def graph_coloring(graph, colors, node, color_map):\n",
        "    if node not in graph:\n",
        "        return True\n",
        "    for color in colors:\n",
        "        if is_safe(graph, node, color, color_map):\n",
        "            color_map[node] = color\n",
        "            if graph_coloring(graph, colors, node + 1, color_map):\n",
        "                return True\n",
        "            color_map[node] = None\n",
        "    return False\n",
        "\n",
        "# Example usage:\n",
        "graph = {\n",
        "    0: [1, 2],\n",
        "    1: [0, 2, 3],\n",
        "    2: [0, 1, 3],\n",
        "    3: [1, 2]\n",
        "}\n",
        "num_colors = 3\n",
        "color_map = {}\n",
        "if graph_coloring(graph, range(num_colors), 0, color_map):\n",
        "    print(\"Graph can be colored with\", num_colors, \"colors.\")\n",
        "    print(\"Color Map:\", color_map)\n",
        "else:\n",
        "    print(\"Graph cannot be colored with\", num_colors, \"colors.\")\n"
      ],
      "metadata": {
        "id": "hpNXEsmluXQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Algorithmic Techniques:**\n",
        "\n",
        "**Explanation:** Algorithmic techniques are strategies used to design efficient algorithms. Common techniques include divide and conquer, backtracking, and randomized algorithms.\n",
        "\n",
        "**Code Implementations:**\n",
        "\n",
        "**Divide and Conquer (Merge Sort):**"
      ],
      "metadata": {
        "id": "xnlhTfHJuacy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_sort(arr):\n",
        "    if len(arr) <= 1:\n",
        "        return arr\n",
        "    mid = len(arr) // 2\n",
        "    left = merge_sort(arr[:mid])\n",
        "    right = merge_sort(arr[mid:])\n",
        "    return merge(left, right)\n",
        "\n",
        "def merge(left, right):\n",
        "    result = []\n",
        "    i = j = 0\n",
        "    while i < len(left) and j < len(right):\n",
        "        if left[i] < right[j]:\n",
        "            result.append(left[i])\n",
        "            i += 1\n",
        "        else:\n",
        "            result.append(right[j])\n",
        "            j += 1\n",
        "    result.extend(left[i:])\n",
        "    result.extend(right[j:])\n",
        "    return result\n",
        "\n",
        "# Example usage:\n",
        "arr = [5, 2, 8, 1, 3]\n",
        "sorted_arr = merge_sort(arr)\n",
        "print(\"Sorted Array:\", sorted_arr)\n"
      ],
      "metadata": {
        "id": "UDL3yaW5uiWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Backtracking (N-Queens Problem):**"
      ],
      "metadata": {
        "id": "D77prz4uukH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_safe(board, row, col):\n",
        "    for i in range(col):\n",
        "        if board[row][i] == 1:\n",
        "            return False\n",
        "    for i, j in zip(range(row, -1, -1), range(col, -1, -1)):\n",
        "        if board[i][j] == 1:\n",
        "            return False\n",
        "    for i, j in zip(range(row, len(board)), range(col, -1, -1)):\n",
        "        if board[i][j] == 1:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def solve_n_queens_util(board, col):\n",
        "    if col >= len(board):\n",
        "        return True\n",
        "    for i in range(len(board)):\n",
        "        if is_safe(board, i, col):\n",
        "            board[i][col] = 1\n",
        "            if solve_n_queens_util(board, col + 1):\n",
        "                return True\n",
        "            board[i][col] = 0\n",
        "    return False\n",
        "\n",
        "def solve_n_queens(n):\n",
        "    board = [[0] * n for _ in range(n)]\n",
        "    if not solve_n_queens_util(board, 0):\n",
        "        return \"No solution exists.\"\n",
        "    return board\n",
        "\n",
        "# Example usage:\n",
        "n = 4\n",
        "solution = solve_n_queens(n)\n",
        "if solution != \"No solution exists.\":\n",
        "    for row in solution:\n",
        "        print(row)\n",
        "else:\n",
        "    print(solution)\n"
      ],
      "metadata": {
        "id": "Ag8asailunEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Randomized Algorithms (Quick Sort):**"
      ],
      "metadata": {
        "id": "ksln0ELLuofQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def quick_sort(arr):\n",
        "    if len(arr) <= 1:\n",
        "        return arr\n",
        "    pivot = random.choice(arr)\n",
        "    left = [x for x in arr if x < pivot]\n",
        "    equal = [x for x in arr if x == pivot]\n",
        "    right = [x for x in arr if x > pivot]\n",
        "    return quick_sort(left) + equal + quick_sort(right)\n",
        "\n",
        "# Example usage:\n",
        "arr = [5, 2, 8, 1, 3]\n",
        "sorted_arr = quick_sort(arr)\n",
        "print(\"Sorted Array:\", sorted_arr)\n"
      ],
      "metadata": {
        "id": "Tjg1o3pvurgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's consider including more specialized or domain-specific topics. Here are a few topics:\n",
        "\n",
        "1. **Dynamic Programming (Advanced)**:\n",
        "   - Explore more advanced dynamic programming techniques such as memoization, tabulation, and optimizing space complexity.\n",
        "   - Cover dynamic programming problems related to strings, arrays, trees, and graphs.\n",
        "\n",
        "2. **Advanced Graph Algorithms**:\n",
        "   - Dive deeper into specific graph algorithms such as Eulerian paths and cycles, Hamiltonian paths and cycles, and articulation points and bridges.\n",
        "   - Discuss algorithms for solving problems like network reliability, maximum flow with minimum cost, and graph isomorphism.\n",
        "\n",
        "3. **Computational Geometry**:\n",
        "   - Introduce algorithms and data structures for solving geometric problems, such as convex hull, line intersection, and closest pair of points.\n",
        "   - Cover applications of computational geometry in computer graphics, robotics, and geographic information systems (GIS).\n",
        "\n",
        "4. **Machine Learning Algorithms**:\n",
        "   - Explore fundamental machine learning algorithms such as linear regression, logistic regression, decision trees, and k-nearest neighbors.\n",
        "   - Discuss techniques for model evaluation, hyperparameter tuning, and handling imbalanced data.\n",
        "\n",
        "5. **Natural Language Processing (NLP)**:\n",
        "   - Introduce algorithms and techniques for processing and analyzing natural language text, such as tokenization, part-of-speech tagging, named entity recognition, and sentiment analysis.\n",
        "   - Cover popular libraries and frameworks for NLP, such as NLTK (Natural Language Toolkit) and spaCy.\n",
        "\n",
        "6. **Graph Neural Networks (GNNs)**:\n",
        "   - Explore the intersection of graph theory and machine learning by covering graph neural networks.\n",
        "   - Discuss GNN architectures, message passing algorithms, and applications in tasks like node classification, link prediction, and graph generation.\n",
        "\n",
        "7. **Parallel and Distributed Algorithms**:\n",
        "   - Introduce algorithms designed for parallel and distributed computing environments, such as parallel sorting, parallel matrix multiplication, and distributed consensus algorithms.\n",
        "   - Cover frameworks and libraries for parallel and distributed computing, such as MPI (Message Passing Interface) and Apache Spark.\n",
        "\n",
        "8. **Bioinformatics Algorithms**:\n",
        "   - Explore algorithms and techniques used in bioinformatics for analyzing biological data, such as sequence alignment, genome assembly, and phylogenetic tree reconstruction.\n",
        "   - Discuss applications of bioinformatics algorithms in genetics, molecular biology, and personalized medicine.\n",
        "\n",
        "9. **Quantum Computing Algorithms**:\n",
        "   - Introduce algorithms and techniques designed for quantum computing platforms, such as Shor's algorithm for integer factorization, Grover's algorithm for unstructured search, and quantum phase estimation.\n",
        "   - Discuss quantum computing hardware and software platforms, as well as potential applications in cryptography, optimization, and simulation.\n",
        "\n",
        "10. **Reinforcement Learning Algorithms**:\n",
        "    - Explore reinforcement learning algorithms such as Q-learning, deep Q-networks (DQN), policy gradients, and actor-critic methods.\n",
        "    - Cover applications of reinforcement learning in robotics, game playing, autonomous systems, and finance.\n",
        "\n",
        "Choose topics based on your interests, audience's background, and relevance to current trends in technology and research. Each of these topics offers a rich area for exploration and learning in computer science and related fields."
      ],
      "metadata": {
        "id": "0_A1BLVIy7x8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dynamic Programming (Advanced):**\n",
        "Explanation: Advanced dynamic programming techniques focus on optimizing both time and space complexities further. This involves using techniques like memoization (top-down approach) and tabulation (bottom-up approach) to store and reuse intermediate results efficiently. Advanced dynamic programming algorithms often solve complex optimization problems by breaking them down into smaller subproblems and combining the solutions.\n",
        "\n",
        "*Code Implementation:* Below is an example implementation of the Fibonacci sequence using memoization (top-down approach) in Python:"
      ],
      "metadata": {
        "id": "k2bimCOrT2Dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using memoization (top-down approach) for Fibonacci sequence\n",
        "def fibonacci_memo(n, memo={}):\n",
        "    if n in memo:\n",
        "        return memo[n]\n",
        "    if n <= 1:\n",
        "        return n\n",
        "    memo[n] = fibonacci_memo(n - 1, memo) + fibonacci_memo(n - 2, memo)\n",
        "    return memo[n]\n",
        "\n",
        "# Example usage:\n",
        "n = 10\n",
        "print(\"Fibonacci sequence up to\", n, \":\", [fibonacci_memo(i) for i in range(n)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA2v5tefZ8c4",
        "outputId": "81e25166-219e-4da5-a7b7-4be4d3d9b65f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fibonacci sequence up to 10 : [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this implementation, fibonacci_memo() function calculates the nth Fibonacci number using memoization to store previously computed results. By storing intermediate results in a memoization dictionary, the function avoids redundant computations and significantly improves the efficiency of calculating Fibonacci numbers.\n",
        "\n",
        "Advanced dynamic programming techniques are essential for solving complex optimization problems efficiently in various domains, including algorithm design, computational biology, economics, and operations research. These techniques enable the efficient solution of problems that may otherwise be computationally infeasible with brute-force or naive approaches."
      ],
      "metadata": {
        "id": "kJHEbAIbaFmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Advanced Graph Algorithms:**\n",
        "\n",
        "Advanced Graph Algorithms delve deeper into specific graph theory concepts and problem-solving techniques beyond basic traversal and shortest path algorithms. These algorithms are often used to tackle more complex optimization problems and are essential in various domains such as network optimization, computational biology, and social network analysis.\n",
        "\n",
        "*Eulerian Paths and Cycles:*\n",
        "\n",
        "An Eulerian path is a path in a graph that visits every edge exactly once.\n",
        "An Eulerian cycle is a cycle in a graph that visits every edge exactly once and returns to the starting vertex.\n",
        "Eulerian paths and cycles exist in graphs where all vertices have even degrees.\n",
        "Hierholzer's algorithm can be used to find Eulerian paths and cycles efficiently.\n",
        "\n",
        "*Hamiltonian Paths and Cycles:*\n",
        "\n",
        "A Hamiltonian path is a path in a graph that visits every vertex exactly once.\n",
        "A Hamiltonian cycle is a cycle in a graph that visits every vertex exactly once and returns to the starting vertex.\n",
        "Finding Hamiltonian paths and cycles is a known NP-complete problem, and no efficient algorithm exists for general graphs.\n",
        "Backtracking or dynamic programming approaches can be used to solve specific cases or find approximate solutions.\n",
        "\n",
        "*Articulation Points and Bridges:*\n",
        "\n",
        "An articulation point (or cut vertex) is a vertex whose removal disconnects the graph.\n",
        "A bridge (or cut edge) is an edge whose removal disconnects the graph.\n",
        "Tarjan's algorithm or depth-first search (DFS) can be used to find articulation points and bridges efficiently.\n",
        "\n",
        "*Network Reliability:*\n",
        "\n",
        "Network reliability algorithms determine the probability that a network remains connected given the failure of individual components.\n",
        "These algorithms are used in reliability engineering, telecommunications, and infrastructure planning.\n",
        "Techniques such as Monte Carlo simulation, dynamic programming, or enumeration can be employed to compute network reliability.\n",
        "\n",
        "*Code Implementation Example:*\n",
        "\n",
        "Here's a Python implementation of Tarjan's algorithm to find articulation points and bridges in an undirected graph:"
      ],
      "metadata": {
        "id": "lW71FMEcaRtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def articulation_points_and_bridges(graph):\n",
        "    def dfs(u, parent):\n",
        "        nonlocal time\n",
        "        low[u] = disc[u] = time\n",
        "        time += 1\n",
        "        children = 0\n",
        "        for v in graph[u]:\n",
        "            if disc[v] == -1:\n",
        "                children += 1\n",
        "                parent[v] = u\n",
        "                dfs(v, parent)\n",
        "                low[u] = min(low[u], low[v])\n",
        "                if low[v] > disc[u]:\n",
        "                    bridges.append((u, v))\n",
        "                if parent[u] == -1 and children > 1:\n",
        "                    articulation_points.add(u)\n",
        "                if parent[u] != -1 and low[v] >= disc[u]:\n",
        "                    articulation_points.add(u)\n",
        "            elif v != parent[u]:\n",
        "                low[u] = min(low[u], disc[v])\n",
        "\n",
        "    n = len(graph)\n",
        "    disc = [-1] * n\n",
        "    low = [-1] * n\n",
        "    parent = [-1] * n\n",
        "    time = 0\n",
        "    articulation_points = set()\n",
        "    bridges = []\n",
        "\n",
        "    for u in range(n):\n",
        "        if disc[u] == -1:\n",
        "            dfs(u, parent)\n",
        "\n",
        "    return articulation_points, bridges\n",
        "\n",
        "# Example usage:\n",
        "graph = {\n",
        "    0: [1, 2],\n",
        "    1: [0, 2, 3],\n",
        "    2: [0, 1, 3],\n",
        "    3: [1, 2]\n",
        "}\n",
        "articulation_points, bridges = articulation_points_and_bridges(graph)\n",
        "print(\"Articulation Points:\", articulation_points)\n",
        "print(\"Bridges:\", bridges)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wQala2Ya2OC",
        "outputId": "276cd913-7a8a-4770-a57a-579aca383f0a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Articulation Points: set()\n",
            "Bridges: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This implementation demonstrates how to find articulation points and bridges in an undirected graph using Tarjan's algorithm. It provides insights into identifying critical vertices and edges in network analysis and infrastructure planning."
      ],
      "metadata": {
        "id": "jEqlrNoHa_7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Computational Geometry**\n",
        "\n",
        "It is a branch of computer science that deals with algorithms and data structures for solving geometric problems. These problems often involve geometric objects such as points, lines, polygons, and circles, and the goal is to develop efficient algorithms to analyze and manipulate these objects.\n",
        "\n",
        "**Algorithms and Data Structures:**\n",
        "\n",
        "*Convex Hull:*\n",
        "\n",
        "Convex hull is the smallest convex polygon that encloses all given points in a plane.\n",
        "One common algorithm to find the convex hull is the Graham scan algorithm."
      ],
      "metadata": {
        "id": "YeJv-5tNc6wM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import cmp_to_key\n",
        "\n",
        "def orientation(p, q, r):\n",
        "    val = (q[1] - p[1]) * (r[0] - q[0]) - (q[0] - p[0]) * (r[1] - q[1])\n",
        "    if val == 0:\n",
        "        return 0\n",
        "    return 1 if val > 0 else -1\n",
        "\n",
        "def convex_hull(points):\n",
        "    n = len(points)\n",
        "    points = sorted(points)\n",
        "    hull = []\n",
        "\n",
        "    def compare(p1, p2):\n",
        "        o = orientation(points[0], p1, p2)\n",
        "        if o == 0:\n",
        "            return -1 if (p1[0] + p1[1]) < (p2[0] + p2[1]) else 1\n",
        "        return -o\n",
        "\n",
        "    hull.append(points[0])\n",
        "    hull.append(points[1])\n",
        "\n",
        "    for i in range(2, n):\n",
        "        while len(hull) >= 2 and orientation(hull[-2], hull[-1], points[i]) != -1:\n",
        "            hull.pop()\n",
        "        hull.append(points[i])\n",
        "\n",
        "    return hull\n",
        "\n",
        "# Example usage:\n",
        "points = [(0, 3), (1, 1), (2, 2), (4, 4), (0, 0), (1, 2), (3, 1), (3, 3)]\n",
        "convex_hull_points = convex_hull(points)\n",
        "print(\"Convex Hull:\", convex_hull_points)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_KtDp5WdfbP",
        "outputId": "704d3976-edb7-442d-e284-46172c1fc45b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convex Hull: [(0, 0), (3, 1), (4, 4)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Line Intersection:*\n",
        "\n",
        "Given two lines represented by their endpoints, determine if they intersect and where.\n",
        "One common algorithm is the sweep line algorithm."
      ],
      "metadata": {
        "id": "tWJnK4uadiPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def on_segment(p, q, r):\n",
        "    return min(p[0], r[0]) <= q[0] <= max(p[0], r[0]) and min(p[1], r[1]) <= q[1] <= max(p[1], r[1])\n",
        "\n",
        "def orientation(p, q, r):\n",
        "    val = (q[1] - p[1]) * (r[0] - q[0]) - (q[0] - p[0]) * (r[1] - q[1])\n",
        "    if val == 0:\n",
        "        return 0\n",
        "    return 1 if val > 0 else -1\n",
        "\n",
        "def do_intersect(p1, q1, p2, q2):\n",
        "    o1 = orientation(p1, q1, p2)\n",
        "    o2 = orientation(p1, q1, q2)\n",
        "    o3 = orientation(p2, q2, p1)\n",
        "    o4 = orientation(p2, q2, q1)\n",
        "\n",
        "    if o1 != o2 and o3 != o4:\n",
        "        return True\n",
        "\n",
        "    if o1 == 0 and on_segment(p1, p2, q1):\n",
        "        return True\n",
        "    if o2 == 0 and on_segment(p1, q2, q1):\n",
        "        return True\n",
        "    if o3 == 0 and on_segment(p2, p1, q2):\n",
        "        return True\n",
        "    if o4 == 0 and on_segment(p2, q1, q2):\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "# Example usage:\n",
        "line1 = [(1, 1), (10, 1)]\n",
        "line2 = [(1, 2), (10, 2)]\n",
        "if do_intersect(*line1, *line2):\n",
        "    print(\"Lines intersect.\")\n",
        "else:\n",
        "    print(\"Lines do not intersect.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Neooyih1dVMS",
        "outputId": "670807a7-46f0-44b6-ab6d-a996f62a2c33"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines do not intersect.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Closest Pair of Points:*\n",
        "\n",
        "Given a set of points, find the pair of points with the smallest distance between them.\n",
        "One common algorithm is the divide and conquer approach."
      ],
      "metadata": {
        "id": "CQcb9sxMdqWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def dist(p1, p2):\n",
        "    return math.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)\n",
        "\n",
        "def brute_force(points):\n",
        "    min_dist = float('inf')\n",
        "    for i in range(len(points)):\n",
        "        for j in range(i + 1, len(points)):\n",
        "            min_dist = min(min_dist, dist(points[i], points[j]))\n",
        "    return min_dist\n",
        "\n",
        "def closest_pair(points):\n",
        "    n = len(points)\n",
        "    if n <= 3:\n",
        "        return brute_force(points)\n",
        "\n",
        "    mid = n // 2\n",
        "    mid_point = points[mid]\n",
        "\n",
        "    left_points = points[:mid]\n",
        "    right_points = points[mid:]\n",
        "\n",
        "    d_left = closest_pair(left_points)\n",
        "    d_right = closest_pair(right_points)\n",
        "\n",
        "    d = min(d_left, d_right)\n",
        "\n",
        "    strip = [point for point in points if abs(point[0] - mid_point[0]) < d]\n",
        "\n",
        "    strip.sort(key=lambda x: x[1])\n",
        "\n",
        "    min_strip = float('inf')\n",
        "    for i in range(len(strip)):\n",
        "        j = i + 1\n",
        "        while j < len(strip) and (strip[j][1] - strip[i][1]) < min_strip:\n",
        "            min_strip = min(min_strip, dist(strip[i], strip[j]))\n",
        "            j += 1\n",
        "\n",
        "    return min(d, min_strip)\n",
        "\n",
        "# Example usage:\n",
        "points = [(2, 3), (12, 30), (40, 50), (5, 1), (12, 10), (3, 4)]\n",
        "min_dist = closest_pair(sorted(points, key=lambda x: x[0]))\n",
        "print(\"Closest Pair Distance:\", min_dist)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDlZHKKYdvNK",
        "outputId": "dcc686d6-db1b-4fcc-cf87-df623df18dfd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closest Pair Distance: 1.4142135623730951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applications:**\n",
        "Computational geometry finds applications in various fields, including:\n",
        "\n",
        "*Computer Graphics:* Used for rendering 2D and 3D graphics, collision detection, and geometric modeling.\n",
        "*Robotics:* Essential for robot motion planning, obstacle avoidance, and localization.\n",
        "*Geographic Information Systems (GIS):* Utilized in mapping, spatial analysis, and route planning for navigation systems.\n",
        "\n",
        "These applications rely on computational geometry algorithms to efficiently process and analyze geometric data, enabling a wide range of real-world applications and technologies."
      ],
      "metadata": {
        "id": "h-Lo3XMFdy-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Learning Algorithms:**\n",
        "\n",
        "Machine learning algorithms enable computers to learn from data and make predictions or decisions without being explicitly programmed. Here's a brief explanation of fundamental machine learning algorithms along with code implementations for each:\n",
        "\n",
        "*Linear Regression:*\n",
        "\n",
        "Linear regression is a supervised learning algorithm used for predicting the value of a continuous variable based on one or more input features. It models the relationship between the independent variables and the dependent variable as a linear equation.\n",
        "Example Code Implementation (using scikit-learn):"
      ],
      "metadata": {
        "id": "vLmFoLa5eAF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1], [2], [3], [4]])\n",
        "y = np.array([2, 4, 6, 8])\n",
        "\n",
        "# Create and fit the model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Model evaluation\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KLjeuBQef33",
        "outputId": "b9ee5f97-bf21-4e29-c1a1-35b8b0eac300"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Logistic Regression:*\n",
        "\n",
        "Logistic regression is a classification algorithm used for binary classification tasks. It models the probability of the binary outcome as a logistic function of the input features.\n",
        "Example Code Implementation (using scikit-learn):"
      ],
      "metadata": {
        "id": "NReVRnHreidg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1], [2], [3], [4]])\n",
        "y = np.array([0, 0, 1, 1])\n",
        "\n",
        "# Create and fit the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Model evaluation\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXhUmU85emu0",
        "outputId": "036a281b-5c1b-4777-b018-985be47d8f50"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Decision Trees:*\n",
        "\n",
        "Decision trees are versatile supervised learning algorithms used for both classification and regression tasks. They partition the feature space into regions and make decisions based on the feature values.\n",
        "Example Code Implementation (using scikit-learn):"
      ],
      "metadata": {
        "id": "JQMkdUhNeo3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1], [2], [3], [4]])\n",
        "y = np.array([0, 0, 1, 1])\n",
        "\n",
        "# Create and fit the model\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Model evaluation\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDpHYKZmesZm",
        "outputId": "75164a28-a82f-4d1d-de8d-03bb193c8333"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*K-Nearest Neighbors (KNN):*\n",
        "\n",
        "K-nearest neighbors is a simple yet effective classification and regression algorithm. It predicts the label or value of a new data point based on the majority vote or mean of its k-nearest neighbors in the feature space.\n",
        "Example Code Implementation (using scikit-learn):"
      ],
      "metadata": {
        "id": "fm4SJl04euYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1], [2], [3], [4]])\n",
        "y = np.array([0, 0, 1, 1])\n",
        "\n",
        "# Create and fit the model\n",
        "model = KNeighborsClassifier(n_neighbors=3)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Model evaluation\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWvRFMlMew3Q",
        "outputId": "cfa0667c-754a-4813-e895-87eb0297466b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Techniques for Model Evaluation, Hyperparameter Tuning, and Handling Imbalanced Data:**\n",
        "\n",
        "*Model evaluation:* Techniques such as cross-validation, precision, recall, F1-score, and ROC curves are commonly used for evaluating machine learning models.\n",
        "*Hyperparameter tuning:* Grid search, random search, and Bayesian optimization are techniques used to find the optimal hyperparameters for a machine learning model.\n",
        "*Handling imbalanced data:* Techniques such as resampling (oversampling, undersampling), using appropriate evaluation metrics (e.g., precision-recall curve), and ensemble methods (e.g., SMOTE, ADASYN) can be used to handle imbalanced datasets effectively.\n",
        "\n",
        "These code implementations and brief explanations provide an overview of fundamental machine learning algorithms, along with techniques for model evaluation, hyperparameter tuning, and handling imbalanced data. Further exploration and experimentation with these algorithms and techniques can deepen understanding and proficiency in machine learning."
      ],
      "metadata": {
        "id": "_SHkSPo1e5bZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natural Language Processing (NLP):**\n",
        "\n",
        "Natural Language Processing (NLP) involves the use of computational techniques to understand, interpret, and generate human language. It encompasses a wide range of tasks, from basic text processing to advanced language understanding and generation. Some common NLP tasks include tokenization, part-of-speech tagging, named entity recognition, and sentiment analysis.\n",
        "\n",
        "*Tokenization* is the process of breaking down text into smaller units, such as words or subwords. It is a fundamental preprocessing step in NLP tasks.\n",
        "\n",
        "*Part-of-speech (POS) tagging* involves assigning grammatical categories (e.g., noun, verb, adjective) to words in a sentence. This information is crucial for many downstream NLP tasks.\n",
        "\n",
        "*Named entity recognition (NER)* identifies and classifies named entities (e.g., persons, organizations, locations) mentioned in text. It helps in extracting structured information from unstructured text.\n",
        "\n",
        "*Sentiment analysis* aims to determine the sentiment or opinion expressed in a piece of text. It can be used to analyze social media posts, product reviews, and customer feedback.\n",
        "\n",
        "Popular libraries and frameworks for NLP include NLTK (Natural Language Toolkit) and spaCy. These libraries provide efficient implementations of various NLP algorithms and tools for working with text data.\n",
        "\n",
        "**Code Implementation:**\n",
        "\n",
        "Below is a brief code implementation demonstrating tokenization and part-of-speech tagging using NLTK:"
      ],
      "metadata": {
        "id": "jro0A7aQfABz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk import pos_tag\n",
        "\n",
        "# Sample text\n",
        "text = \"Natural language processing is a field of study in artificial intelligence.\"\n",
        "\n",
        "# Tokenization\n",
        "tokens = word_tokenize(text)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "# Part-of-speech tagging\n",
        "pos_tags = pos_tag(tokens)\n",
        "print(\"Part-of-Speech Tags:\", pos_tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTUEiV-Xff8Y",
        "outputId": "ed5f22d2-2a0b-4686-a488-a88c0da70f6b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['Natural', 'language', 'processing', 'is', 'a', 'field', 'of', 'study', 'in', 'artificial', 'intelligence', '.']\n",
            "Part-of-Speech Tags: [('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('field', 'NN'), ('of', 'IN'), ('study', 'NN'), ('in', 'IN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet demonstrates how to tokenize a sentence into words and then perform part-of-speech tagging to assign grammatical categories to each word using NLTK.\n",
        "\n",
        "Similarly, spaCy provides a powerful and efficient NLP toolkit for various tasks, including tokenization, POS tagging, NER, and dependency parsing.\n",
        "\n",
        "NLP algorithms and techniques, along with libraries like NLTK and spaCy, play a crucial role in various applications such as chatbots, machine translation, text summarization, information extraction, and more."
      ],
      "metadata": {
        "id": "OAB33cQ8gk6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GNN Architectures:**\n",
        "\n",
        "Graph Neural Networks (GNNs) represent a class of neural network architectures designed to operate on graph-structured data. They extend traditional neural networks to handle irregular and non-Euclidean data representations, making them suitable for tasks involving graphs, such as node classification, link prediction, and graph generation. GNNs leverage the underlying graph structure to extract meaningful features and relationships between nodes.\n",
        "\n",
        "GNN architectures typically consist of multiple layers, each performing message passing between nodes to aggregate information from neighboring nodes. The key components of a GNN architecture include:\n",
        "\n",
        "*Node Embedding Layer:* Converts node features into low-dimensional embeddings.\n",
        "*Message Passing Layers: *Propagate information between nodes by aggregating features from neighboring nodes.\n",
        "*Readout/Pooling Layer:* Aggregates node-level features to compute graph-level representations.\n",
        "*Output Layer:* Produces final predictions or representations based on the learned graph embeddings.\n",
        "\n",
        "**Message Passing Algorithms:**\n",
        "\n",
        "Message passing forms the core operation of GNNs, where nodes exchange information with their neighbors iteratively. The process typically involves the following steps:\n",
        "\n",
        "*Message Generation:* Nodes generate messages based on their features and relationships with neighboring nodes.\n",
        "*Message Aggregation:* Nodes aggregate received messages to update their own representations.\n",
        "*Node Update:* Nodes update their features using aggregated messages and optionally, their own features.\n",
        "*Pooling/Readout:* Graph-level representations are computed by aggregating node representations.\n",
        "\n",
        "**Code Implementation:**\n",
        "Below is a simple implementation of a Graph Neural Network for node classification using PyTorch Geometric, a popular library for working with graph data in PyTorch."
      ],
      "metadata": {
        "id": "lODJnPcwgmMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQl_Ec1siC80",
        "outputId": "106c6e3b-804c-476e-cc37-0570dac811c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cpu.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.2)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cpu.html\n",
            "Collecting torch-sparse\n",
            "  Using cached torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.25.2)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 417, in run\n",
            "    _, build_failures = build(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 320, in build\n",
            "    wheel_file = _build_one(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 194, in _build_one\n",
            "    wheel_path = _build_one_inside_env(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 241, in _build_one_inside_env\n",
            "    wheel_path = build_wheel_legacy(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 83, in build_wheel_legacy\n",
            "    output = call_subprocess(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 207, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1465, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.10/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1218, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
            "    msg = self.format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 943, in format\n",
            "    return fmt.format(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 686, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 636, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 119, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 502, in __init__\n",
            "    self.stack = StackSummary.extract(\n",
            "  File \"/usr/lib/python3.10/traceback.py\", line 353, in extract\n",
            "    limit = getattr(sys, 'tracebacklimit', None)\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cpu.html\n",
            "Collecting torch-cluster\n",
            "  Using cached torch_cluster-1.6.3.tar.gz (54 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-cluster) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-cluster) (1.25.2)\n",
            "Building wheels for collected packages: torch-cluster\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in links: https://pytorch-geometric.com/whl/torch-1.9.0+cpu.html\n",
            "Collecting torch-spline-conv\n",
            "  Using cached torch_spline_conv-1.2.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-spline-conv\n",
            "  Building wheel for torch-spline-conv (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    with self.main_context():\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 142, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/command_context.py\", line 19, in main_context\n",
            "    with self._main_context:\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 576, in __exit__\n",
            "    raise exc_details[1]\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
            "    self.gen.throw(typ, value, traceback)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/temp_dir.py\", line 70, in tempdir_registry\n",
            "    yield _tempdir_registry\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 561, in __exit__\n",
            "    if cb(*exc_details):\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 142, in __exit__\n",
            "    next(self.gen)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/temp_dir.py\", line 31, in global_tempdir_manager\n",
            "    with ExitStack() as stack:\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 576, in __exit__\n",
            "    raise exc_details[1]\n",
            "  File \"/usr/lib/python3.10/contextlib.py\", line 561, in __exit__\n",
            "    if cb(*exc_details):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/temp_dir.py\", line 156, in __exit__\n",
            "    self.cleanup()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/temp_dir.py\", line 173, in cleanup\n",
            "    rmtree(self._path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/tenacity/__init__.py\", line 291, in wrapped_f\n",
            "    return self(f, *args, **kw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/tenacity/__init__.py\", line 381, in __call__\n",
            "    do = self.iter(retry_state=retry_state)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/tenacity/__init__.py\", line 316, in iter\n",
            "    return fut.result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 451, in result\n",
            "    return self.__get_result()\n",
            "  File \"/usr/lib/python3.10/concurrent/futures/_base.py\", line 403, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/tenacity/__init__.py\", line 384, in __call__\n",
            "    result = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/misc.py\", line 130, in rmtree\n",
            "    shutil.rmtree(dir, ignore_errors=ignore_errors, onerror=rmtree_errorhandler)\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 725, in rmtree\n",
            "    _rmtree_safe_fd(fd, path, onerror)\n",
            "  File \"/usr/lib/python3.10/shutil.py\", line 630, in _rmtree_safe_fd\n",
            "    entries = list(scandir_it)\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.9.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "class GNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(GNN, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Load dataset\n",
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "data = dataset[0]\n",
        "\n",
        "# Initialize model\n",
        "model = GNN(input_dim=dataset.num_node_features, hidden_dim=16, output_dim=dataset.num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Train model\n",
        "model.train()\n",
        "for epoch in range(200):\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data.x, data.edge_index)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Evaluate model\n",
        "model.eval()\n",
        "_, pred = model(data.x, data.edge_index).max(dim=1)\n",
        "correct = pred[data.test_mask].eq(data.y[data.test_mask]).sum().item()\n",
        "accuracy = correct / data.test_mask.sum().item()\n",
        "print('Test Accuracy: {:.4f}'.format(accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puqIoaqxh1PU",
        "outputId": "4122ea2f-11b1-4296-daf4-77ee5f3f75e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
            "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
            "Processing...\n",
            "Done!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.7880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code:\n",
        "\n",
        "We define a simple GNN model with two Graph Convolutional Network (GCN) layers.\n",
        "We use the Cora dataset, a benchmark dataset for node classification tasks.\n",
        "We train the model to classify nodes into different classes.\n",
        "Finally, we evaluate the model's performance on a test set and print the accuracy.\n",
        "This example demonstrates how to implement a basic GNN model using PyTorch Geometric for node classification tasks on graph-structured data."
      ],
      "metadata": {
        "id": "m8YLX_1nh77V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parallel and Distributed Algorithms:**\n",
        "\n",
        "Parallel and distributed algorithms are designed to efficiently solve computational problems in parallel and distributed computing environments, where multiple processing units work together to accomplish a task. These algorithms leverage the parallelism and scalability of distributed systems to handle large-scale data processing and computation.\n",
        "\n",
        "**Parallel Sorting:**\n",
        "*Explanation:* Parallel sorting algorithms divide the input data into smaller chunks and sort them concurrently using multiple processors or threads. Once sorted, the chunks are merged to produce the final sorted output.\n",
        "*Code Implementation* (Parallel Merge Sort using Python's 'concurrent.futures'):"
      ],
      "metadata": {
        "id": "0XWaLuK4mFy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def merge_sort(arr):\n",
        "    if len(arr) <= 1:\n",
        "        return arr\n",
        "    mid = len(arr) // 2\n",
        "    left = merge_sort(arr[:mid])\n",
        "    right = merge_sort(arr[mid:])\n",
        "    return merge(left, right)\n",
        "\n",
        "def merge(left, right):\n",
        "    result = []\n",
        "    i = j = 0\n",
        "    while i < len(left) and j < len(right):\n",
        "        if left[i] < right[j]:\n",
        "            result.append(left[i])\n",
        "            i += 1\n",
        "        else:\n",
        "            result.append(right[j])\n",
        "            j += 1\n",
        "    result.extend(left[i:])\n",
        "    result.extend(right[j:])\n",
        "    return result\n",
        "\n",
        "def parallel_merge_sort(arr):\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        return list(executor.map(merge_sort, arr))\n",
        "\n",
        "# Example usage:\n",
        "arr = [[5, 2, 8, 1, 3], [9, 6, 2, 7, 4]]\n",
        "sorted_arr = parallel_merge_sort(arr)\n",
        "print(\"Sorted Arrays:\", sorted_arr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL4yH4m7moMF",
        "outputId": "e043ad69-9956-4301-fa83-e5f5d8c277ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorted Arrays: [[1, 2, 3, 5, 8], [2, 4, 6, 7, 9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parallel Matrix Multiplication:**\n",
        "\n",
        "*Explanation:* Parallel matrix multiplication algorithms distribute the computation of matrix multiplication across multiple processors or nodes in a distributed system, allowing for faster computation of large matrices.\n",
        "*Code Implementation* (Parallel Matrix Multiplication using Python's 'concurrent.futures'):"
      ],
      "metadata": {
        "id": "OZWlxOrQmsMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def parallel_matrix_multiplication(A, B):\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        return executor.submit(np.dot, A, B).result()\n",
        "\n",
        "# Example usage:\n",
        "A = np.random.randint(0, 10, (3, 3))\n",
        "B = np.random.randint(0, 10, (3, 3))\n",
        "result = parallel_matrix_multiplication(A, B)\n",
        "print(\"Result of Matrix Multiplication:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G3X_c_hmz1t",
        "outputId": "ebde7b05-9083-4d5a-d2b3-f0a71679eaef"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result of Matrix Multiplication:\n",
            "[[ 71 105  95]\n",
            " [ 33  60  45]\n",
            " [ 83 145  85]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distributed Consensus Algorithms:**\n",
        "\n",
        "*Explanation:* Distributed consensus algorithms ensure that distributed processes or nodes in a system agree on a single value or decision, even in the presence of failures or network partitions. Examples include the Paxos algorithm and the Raft consensus algorithm.\n",
        "\n",
        "*Code Implementation:* Consensus algorithms typically involve complex protocols and are often implemented using specialized libraries or frameworks like Apache ZooKeeper or etcd. Below is a simplified example using Python's 'socket' module for achieving consensus among multiple nodes:"
      ],
      "metadata": {
        "id": "SvzIXDCfm2k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import socket\n",
        "import threading\n",
        "\n",
        "def handle_client(conn, addr):\n",
        "    # Receive data from the client\n",
        "    data = conn.recv(1024)\n",
        "    # Perform some computation or validation\n",
        "    # Send back the agreed value or decision\n",
        "    conn.send(b\"Agreed value\")\n",
        "    conn.close()\n",
        "\n",
        "def start_server():\n",
        "    host = '127.0.0.1'\n",
        "    port = 12345\n",
        "    server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "    server.bind((host, port))\n",
        "    server.listen(5)\n",
        "    print(\"Server listening on port\", port)\n",
        "    while True:\n",
        "        conn, addr = server.accept()\n",
        "        threading.Thread(target=handle_client, args=(conn, addr)).start()\n",
        "\n",
        "# Example usage:\n",
        "start_server()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "Er0W4Y7tm_Rr",
        "outputId": "70554bd3-7427-45ae-bca6-4a9c4876cd82"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server listening on port 12345\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-b7a02225a2eb>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Example usage:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mstart_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-b7a02225a2eb>\u001b[0m in \u001b[0;36mstart_server\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Server listening on port\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandle_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36maccept\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mFor\u001b[0m \u001b[0mIP\u001b[0m \u001b[0msockets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0maddress\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhostaddr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maddr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accept\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileno\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;31m# Issue #7995: if no default timeout is set and the listening\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frameworks and Libraries:**\n",
        "\n",
        "**MPI (Message Passing Interface):** MPI is a standard communication protocol used in parallel computing environments. It provides a set of functions for message passing between parallel processes or nodes.\n",
        "\n",
        "**Apache Spark:** Apache Spark is a distributed computing framework that provides APIs for processing large-scale data across clusters. It supports parallel processing and fault tolerance, making it suitable for various data analytics and machine learning tasks.\n",
        "\n",
        "These implementations demonstrate how parallel and distributed algorithms can be applied to solve common computational problems efficiently in parallel and distributed computing environments. The examples cover parallel sorting, parallel matrix multiplication, and a simplified version of distributed consensus algorithms, along with mentions of popular frameworks and libraries used in this domain."
      ],
      "metadata": {
        "id": "skQEqmA1nBEK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bioinformatics Algorithms:**\n",
        "\n",
        "Bioinformatics algorithms are computational techniques used to analyze biological data, particularly in fields like genetics, molecular biology, and personalized medicine. These algorithms play a crucial role in understanding biological processes, identifying genetic variations, and developing treatments for diseases. Here's a brief overview along with a code implementation of a common bioinformatics algorithm: sequence alignment.\n",
        "\n",
        "**Sequence Alignment:**\n",
        "\n",
        "*Explanation:*\n",
        "Sequence alignment is the process of arranging two or more biological sequences (such as DNA, RNA, or protein sequences) to identify regions of similarity. This similarity can reveal evolutionary relationships, functional domains, and mutations between sequences.\n",
        "\n",
        "*Code Implementation:*\n",
        "Below is a basic implementation of the Needleman-Wunsch algorithm for global sequence alignment:"
      ],
      "metadata": {
        "id": "eRn5uwDurdW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def needleman_wunsch(seq1, seq2, match_score=1, mismatch_penalty=-1, gap_penalty=-1):\n",
        "    # Initialize the score matrix\n",
        "    rows = len(seq1) + 1\n",
        "    cols = len(seq2) + 1\n",
        "    score_matrix = [[0] * cols for _ in range(rows)]\n",
        "\n",
        "    # Initialize the first row and column with gap penalties\n",
        "    for i in range(rows):\n",
        "        score_matrix[i][0] = i * gap_penalty\n",
        "    for j in range(cols):\n",
        "        score_matrix[0][j] = j * gap_penalty\n",
        "\n",
        "    # Fill in the score matrix\n",
        "    for i in range(1, rows):\n",
        "        for j in range(1, cols):\n",
        "            if seq1[i - 1] == seq2[j - 1]:\n",
        "                match = score_matrix[i - 1][j - 1] + match_score\n",
        "            else:\n",
        "                match = score_matrix[i - 1][j - 1] + mismatch_penalty\n",
        "            delete = score_matrix[i - 1][j] + gap_penalty\n",
        "            insert = score_matrix[i][j - 1] + gap_penalty\n",
        "            score_matrix[i][j] = max(match, delete, insert)\n",
        "\n",
        "    # Traceback to find the alignment\n",
        "    alignment_seq1 = []\n",
        "    alignment_seq2 = []\n",
        "    i, j = rows - 1, cols - 1\n",
        "    while i > 0 and j > 0:\n",
        "        if seq1[i - 1] == seq2[j - 1]:\n",
        "            alignment_seq1.append(seq1[i - 1])\n",
        "            alignment_seq2.append(seq2[j - 1])\n",
        "            i -= 1\n",
        "            j -= 1\n",
        "        elif score_matrix[i][j] == score_matrix[i - 1][j - 1] + mismatch_penalty:\n",
        "            alignment_seq1.append(seq1[i - 1])\n",
        "            alignment_seq2.append(seq2[j - 1])\n",
        "            i -= 1\n",
        "            j -= 1\n",
        "        elif score_matrix[i][j] == score_matrix[i - 1][j] + gap_penalty:\n",
        "            alignment_seq1.append(seq1[i - 1])\n",
        "            alignment_seq2.append('-')\n",
        "            i -= 1\n",
        "        else:\n",
        "            alignment_seq1.append('-')\n",
        "            alignment_seq2.append(seq2[j - 1])\n",
        "            j -= 1\n",
        "    while i > 0:\n",
        "        alignment_seq1.append(seq1[i - 1])\n",
        "        alignment_seq2.append('-')\n",
        "        i -= 1\n",
        "    while j > 0:\n",
        "        alignment_seq1.append('-')\n",
        "        alignment_seq2.append(seq2[j - 1])\n",
        "        j -= 1\n",
        "\n",
        "    alignment_seq1.reverse()\n",
        "    alignment_seq2.reverse()\n",
        "\n",
        "    return ''.join(alignment_seq1), ''.join(alignment_seq2)\n",
        "\n",
        "# Example usage:\n",
        "seq1 = \"AGTACGCA\"\n",
        "seq2 = \"TATGC\"\n",
        "alignment1, alignment2 = needleman_wunsch(seq1, seq2)\n",
        "print(\"Sequence 1 Alignment:\", alignment1)\n",
        "print(\"Sequence 2 Alignment:\", alignment2)\n"
      ],
      "metadata": {
        "id": "gUxzBOvbr9CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0h8tayY5nJuw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code aligns two biological sequences using the Needleman-Wunsch algorithm, providing insights into their similarities and differences. Sequence alignment is fundamental in bioinformatics for various tasks such as identifying homologous genes, detecting mutations, and understanding evolutionary relationships."
      ],
      "metadata": {
        "id": "leNCHgj8sA6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum Computing Algorithms:**\n",
        "\n",
        "Quantum computing algorithms are designed to run on quantum computers, which leverage the principles of quantum mechanics to perform computations. These algorithms exploit unique quantum phenomena such as superposition, entanglement, and quantum interference to solve certain problems more efficiently than classical computers.\n",
        "\n",
        "**Shor's Algorithm for Integer Factorization:**\n",
        "\n",
        "*Explanation:* Shor's algorithm is a quantum algorithm that efficiently factors large integers into their prime factors. It plays a significant role in breaking classical cryptographic schemes such as RSA, which rely on the difficulty of integer factorization.\n",
        "*Code Implementation:* Due to its complexity and the need for a quantum computer, implementing Shor's algorithm in code is not practical in classical computers. However, various quantum computing simulators and libraries provide implementations for educational purposes."
      ],
      "metadata": {
        "id": "OSPMZXPYsDzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install qiskit\n",
        "!pip install qiskit-aer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKHDvCRHvatK",
        "outputId": "b3e2ba13-8668-4e04-9229-26fd4732ff05"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: qiskit in /usr/local/lib/python3.10/dist-packages (1.0.2)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.14.2)\n",
            "Requirement already satisfied: numpy<2,>=1.17 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.11.4)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (1.12)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.3.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit) (5.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit) (4.10.0)\n",
            "Requirement already satisfied: symengine>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit) (6.0.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Collecting qiskit-aer\n",
            "  Downloading qiskit_aer-0.14.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: qiskit>=0.45.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer) (1.11.4)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.10/dist-packages (from qiskit-aer) (5.9.5)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.45.0->qiskit-aer) (0.14.2)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.45.0->qiskit-aer) (1.12)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.45.0->qiskit-aer) (0.3.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.45.0->qiskit-aer) (2.8.2)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.45.0->qiskit-aer) (5.2.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.45.0->qiskit-aer) (4.10.0)\n",
            "Requirement already satisfied: symengine>=0.11 in /usr/local/lib/python3.10/dist-packages (from qiskit>=0.45.0->qiskit-aer) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.0->qiskit>=0.45.0->qiskit-aer) (1.16.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from stevedore>=3.0.0->qiskit>=0.45.0->qiskit-aer) (6.0.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy>=1.3->qiskit>=0.45.0->qiskit-aer) (1.3.0)\n",
            "Installing collected packages: qiskit-aer\n",
            "Successfully installed qiskit-aer-0.14.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import QuantumCircuit, transpile, assemble\n",
        "from qiskit.providers.aer import AerSimulator\n",
        "from qiskit.aqua import QuantumInstance\n",
        "from qiskit.algorithms import Shor\n",
        "\n",
        "\n",
        "# Define the integer to be factored\n",
        "N = 21\n",
        "\n",
        "# Construct a Shor's algorithm instance\n",
        "shor = Shor(N)\n",
        "\n",
        "# Use Aer's qasm_simulator\n",
        "backend = Aer.get_backend('qasm_simulator')\n",
        "\n",
        "# Execute the algorithm\n",
        "result = shor.run(QuantumInstance(backend, shots=1))\n",
        "\n",
        "# Print the results\n",
        "print(\"Factors of\", N, \":\", result.factors)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "F6bwXtWttOrW",
        "outputId": "2ba9288a-9046-42ef-8289-7a0d5acc8f68"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'qiskit.providers.aer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-c6c80ab1e084>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantumCircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massemble\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAerSimulator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maqua\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantumInstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mShor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'qiskit.providers.aer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Grover's Algorithm for Unstructured Search:**\n",
        "\n",
        "*Explanation:* Grover's algorithm is a quantum algorithm that performs an unstructured search on an unsorted database, providing a quadratic speedup over classical algorithms. It is used for finding a marked item in an unsorted list or solving similar search problems.\n",
        "\n",
        "*Code Implementation:* Similar to Shor's algorithm, implementing Grover's algorithm requires access to a quantum computer or simulator. However, simplified versions or demonstrations of Grover's algorithm can be implemented in quantum computing libraries such as Qiskit or Cirq."
      ],
      "metadata": {
        "id": "obPeVFELtRqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import QuantumCircuit, Aer, execute\n",
        "from qiskit.visualization import plot_histogram\n",
        "\n",
        "# Define the size of the search space\n",
        "n = 3\n",
        "\n",
        "# Create the Oracle for Grover's algorithm (in this case, searching for the '11' state)\n",
        "oracle = QuantumCircuit(n)\n",
        "oracle.cz(0, 2)\n",
        "oracle.cz(1, 2)\n",
        "\n",
        "# Create the Grover's algorithm circuit\n",
        "grover = QuantumCircuit(n)\n",
        "grover.h(range(n))\n",
        "grover.append(oracle, range(n))\n",
        "grover.barrier()\n",
        "grover.h(range(n))\n",
        "grover.measure_all()\n",
        "\n",
        "# Simulate the circuit using the QASM simulator\n",
        "backend = Aer.get_backend('qasm_simulator')\n",
        "job = execute(grover, backend, shots=1024)\n",
        "result = job.result()\n",
        "\n",
        "# Plot the measurement outcomes\n",
        "counts = result.get_counts()\n",
        "plot_histogram(counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "1-KjM9q2tn-8",
        "outputId": "5340ef35-cd16-4072-ce63-3c7ff7380e89"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'Aer' from 'qiskit' (/usr/local/lib/python3.10/dist-packages/qiskit/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c4833b32282d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantumCircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_histogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define the size of the search space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Aer' from 'qiskit' (/usr/local/lib/python3.10/dist-packages/qiskit/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum Phase Estimation:**\n",
        "\n",
        "*Explanation:* Quantum phase estimation is a quantum algorithm used to estimate the phase eigenvalue of a unitary operator. It forms the basis of many quantum algorithms, including Shor's algorithm and quantum simulations.\n",
        "\n",
        "*Code Implementation:* Implementing quantum phase estimation typically involves constructing quantum circuits using quantum gates to encode the input state and perform the phase estimation process. Libraries like Qiskit and Cirq provide tools for simulating and executing quantum circuits."
      ],
      "metadata": {
        "id": "r_kkQydptodV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import QuantumCircuit, Aer, execute\n",
        "from math import pi\n",
        "\n",
        "# Define the unitary operator (controlled-Z gate)\n",
        "def controlled_Z(circuit, control_qubit, target_qubit, angle):\n",
        "    circuit.cu1(angle, control_qubit, target_qubit)\n",
        "\n",
        "# Define the Quantum Phase Estimation circuit\n",
        "n_qubits = 4\n",
        "qc = QuantumCircuit(n_qubits, n_qubits - 1)\n",
        "qc.h(range(n_qubits - 1))\n",
        "qc.x(n_qubits - 1)\n",
        "for qubit in range(n_qubits - 1):\n",
        "    controlled_Z(qc, qubit, n_qubits - 1, 2 * pi / pow(2, qubit + 1))\n",
        "qc.measure(range(n_qubits - 1), range(n_qubits - 1))\n",
        "\n",
        "# Simulate the circuit using the QASM simulator\n",
        "backend = Aer.get_backend('qasm_simulator')\n",
        "job = execute(qc, backend, shots=1024)\n",
        "result = job.result()\n",
        "\n",
        "# Print the measurement outcomes\n",
        "counts = result.get_counts()\n",
        "print(\"Measurement outcomes:\", counts)\n"
      ],
      "metadata": {
        "id": "Xsc-s8zDtuFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantum Computing Hardware and Software Platforms:**\n",
        "\n",
        "*Explanation:* Quantum computing hardware platforms consist of physical devices that implement quantum bits (qubits) and operations required for quantum computation. Examples include superconducting qubits, trapped ions, and topological qubits.\n",
        "\n",
        "*Code Implementation:* While it's not feasible to directly implement quantum hardware in code, quantum computing software platforms like Qiskit, Cirq, and Quipper provide high-level abstractions and APIs for programming quantum algorithms and simulating their behavior on classical computers."
      ],
      "metadata": {
        "id": "5-WO-Ayitwhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit import QuantumCircuit, Aer, execute\n",
        "\n",
        "# Create a simple quantum circuit\n",
        "qc = QuantumCircuit(2)\n",
        "qc.h(0)\n",
        "qc.cx(0, 1)\n",
        "qc.measure_all()\n",
        "\n",
        "# Simulate the circuit using the QASM simulator\n",
        "backend = Aer.get_backend('qasm_simulator')\n",
        "job = execute(qc, backend, shots=1024)\n",
        "result = job.result()\n",
        "\n",
        "# Print the measurement outcomes\n",
        "counts = result.get_counts()\n",
        "print(\"Measurement outcomes:\", counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "zL0Obzpdt0Sv",
        "outputId": "eac8828c-3834-4a94-c2d4-dcf26eff350a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'Aer' from 'qiskit' (/usr/local/lib/python3.10/dist-packages/qiskit/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-51239876068d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantumCircuit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create a simple quantum circuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mqc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuantumCircuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mqc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Aer' from 'qiskit' (/usr/local/lib/python3.10/dist-packages/qiskit/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hypothetical interface for interacting with quantum hardware platform\n",
        "class QuantumHardwareInterface:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def submit_circuit(self, circuit):\n",
        "        # Submit the quantum circuit for execution on the hardware\n",
        "        pass\n",
        "\n",
        "    def retrieve_results(self):\n",
        "        # Retrieve measurement results from the executed quantum circuit\n",
        "        pass\n",
        "\n",
        "# Example usage of the hypothetical quantum hardware interface\n",
        "qhw_interface = QuantumHardwareInterface()\n",
        "qhw_interface.submit_circuit(qc)  # Submit the quantum circuit for execution\n",
        "results = qhw_interface.retrieve_results()  # Retrieve measurement outcomes\n",
        "print(\"Measurement outcomes from quantum hardware platform:\", results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "EZH3B2qlu52-",
        "outputId": "fceabe81-b1f4-4961-b001-ffde279e205f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'qc' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-dc30052b45b6>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Example usage of the hypothetical quantum hardware interface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mqhw_interface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuantumHardwareInterface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mqhw_interface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqc\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Submit the quantum circuit for execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqhw_interface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Retrieve measurement outcomes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Measurement outcomes from quantum hardware platform:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'qc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Potential Applications:**\n",
        "\n",
        "*Explanation:* Quantum computing has potential applications in various fields, including cryptography, optimization, and simulation. For instance, quantum computers can break classical cryptographic schemes like RSA through integer factorization, solve optimization problems more efficiently using quantum annealing, and simulate quantum systems for understanding chemical reactions and materials science.\n",
        "\n",
        "*Code Implementation:* While code implementations for potential applications of quantum computing can be demonstrated in quantum computing libraries, achieving practical quantum advantage in real-world applications requires advancements in quantum hardware and error correction techniques."
      ],
      "metadata": {
        "id": "G2OfX25bt0pH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from qiskit_nature.drivers import PySCFDriver\n",
        "from qiskit_nature.problems.second_quantization.electronic import ElectronicStructureProblem\n",
        "from qiskit_nature.mappers.second_quantization import ParityMapper\n",
        "from qiskit_nature.converters.second_quantization.qubit_converter import QubitConverter\n",
        "from qiskit_nature.algorithms import NumPyMinimumEigensolver\n",
        "from qiskit_nature.transformers import FreezeCoreTransformer\n",
        "\n",
        "# Define molecular configuration\n",
        "molecule = 'H .0 .0 .0; H .0 .0 0.735'\n",
        "\n",
        "# Use PySCF driver to compute electronic structure of the molecule\n",
        "driver = PySCFDriver(atom=molecule)\n",
        "problem = ElectronicStructureProblem(driver)\n",
        "\n",
        "# Apply freeze core transformation\n",
        "freeze_core = FreezeCoreTransformer(remove_orbitals=[3, 4])\n",
        "problem_frozen = freeze_core.transform(problem)\n",
        "\n",
        "# Map problem to qubits\n",
        "mapper = ParityMapper()\n",
        "converter = QubitConverter(mapper=mapper)\n",
        "qubit_op = converter.convert(problem_frozen.second_q_ops())\n",
        "\n",
        "# Solve the problem using NumPyMinimumEigensolver (classical)\n",
        "solver = NumPyMinimumEigensolver()\n",
        "result = solver.compute_minimum_eigenvalue(qubit_op)\n",
        "print(\"Ground state energy (classical):\", result.eigenvalue)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "rsl1agkst7Ef",
        "outputId": "0a80c874-93ad-4f22-babb-2a9456708f7e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'qiskit_nature'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-711145fb6e6b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_nature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrivers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPySCFDriver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_nature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproblems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_quantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melectronic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElectronicStructureProblem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_nature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_quantization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParityMapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_nature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msecond_quantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqubit_converter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQubitConverter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_nature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumPyMinimumEigensolver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'qiskit_nature'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In summary, quantum computing algorithms leverage quantum principles to solve problems more efficiently than classical algorithms. While implementing these algorithms directly may not be feasible on classical computers, quantum computing libraries and simulators provide tools for understanding and experimenting with quantum algorithms. The potential applications of quantum computing span various domains, promising revolutionary advancements in cryptography, optimization, and scientific simulations."
      ],
      "metadata": {
        "id": "0W4HyQmAt9Hu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reinforcement Learning Algorithms:**\n",
        "\n",
        "Reinforcement Learning (RL) is a type of machine learning paradigm where an agent learns to make sequential decisions by interacting with an environment. The agent receives feedback in the form of rewards or penalties based on its actions, and its goal is to learn a policy that maximizes cumulative rewards over time. Several key algorithms are used in reinforcement learning:\n",
        "\n",
        "1. **Q-Learning**: Q-learning is a model-free reinforcement learning algorithm that learns an action-value function \\( Q(s, a) \\), which estimates the expected cumulative reward of taking action \\( a \\) in state \\( s \\). The agent updates its Q-values based on observed rewards and transitions between states.\n",
        "\n",
        "2. **Deep Q-Networks (DQN)**: DQN is an extension of Q-learning that uses deep neural networks to approximate the Q-values. It addresses the limitations of traditional Q-learning by enabling the agent to handle high-dimensional state spaces, such as images. DQN employs techniques like experience replay and target networks to stabilize training.\n",
        "\n",
        "3. **Policy Gradients**: Policy gradient methods directly learn the policy function \\( \\pi(a|s) \\), which maps states to actions, without explicitly estimating action-values. These algorithms optimize the policy parameters using gradient ascent on the expected cumulative reward. Policy gradient methods are often used in settings with continuous action spaces.\n",
        "\n",
        "4. **Actor-Critic Methods**: Actor-critic methods combine elements of both value-based and policy-based approaches. They maintain two separate networks: an actor network that learns the policy and a critic network that learns the value function. The actor updates the policy based on the advantage or critic's estimate of the value, resulting in more stable learning.\n",
        "\n",
        "**Code Implementation:**\n",
        "\n",
        "Below is a simple implementation of Q-learning algorithm in Python:"
      ],
      "metadata": {
        "id": "ePK352nmyZ4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class QLearning:\n",
        "    def __init__(self, num_states, num_actions, learning_rate=0.1, discount_factor=0.9, epsilon=0.1):\n",
        "        self.num_states = num_states\n",
        "        self.num_actions = num_actions\n",
        "        self.learning_rate = learning_rate\n",
        "        self.discount_factor = discount_factor\n",
        "        self.epsilon = epsilon\n",
        "        self.q_table = np.zeros((num_states, num_actions))\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.uniform(0, 1) < self.epsilon:\n",
        "            return np.random.choice(self.num_actions)\n",
        "        else:\n",
        "            return np.argmax(self.q_table[state])\n",
        "\n",
        "    def update_q_table(self, state, action, reward, next_state):\n",
        "        max_next_q_value = np.max(self.q_table[next_state])\n",
        "        td_target = reward + self.discount_factor * max_next_q_value\n",
        "        td_error = td_target - self.q_table[state, action]\n",
        "        self.q_table[state, action] += self.learning_rate * td_error\n",
        "\n",
        "# Example usage:\n",
        "num_states = 3\n",
        "num_actions = 2\n",
        "q_learning_agent = QLearning(num_states, num_actions)\n",
        "\n",
        "# Training loop\n",
        "for episode in range(1000):\n",
        "    state = 0\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = q_learning_agent.choose_action(state)\n",
        "        next_state = (state + action) % num_states  # Simple environment transition\n",
        "        reward = 1 if next_state == 2 else 0  # Reward for reaching goal state\n",
        "        q_learning_agent.update_q_table(state, action, reward, next_state)\n",
        "        state = next_state\n",
        "        if state == 2:\n",
        "            done = True\n",
        "\n",
        "# Testing loop\n",
        "state = 0\n",
        "path = [state]\n",
        "while state != 2:\n",
        "    action = np.argmax(q_learning_agent.q_table[state])\n",
        "    next_state = (state + action) % num_states\n",
        "    state = next_state\n",
        "    path.append(state)\n",
        "\n",
        "print(\"Optimal path:\", path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0WKxDYqywag",
        "outputId": "98e90ba0-da8d-420e-b1ba-c64f443b3a03"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal path: [0, 1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code implements a basic Q-learning agent that learns to navigate a simple environment with three states and two actions. The agent learns the optimal policy to reach the goal state with the highest cumulative reward."
      ],
      "metadata": {
        "id": "ulSqGsT9yu7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's understand some additional topics:\n",
        "\n",
        "1. **Algorithm Analysis (Advanced)**:\n",
        "   - Dive deeper into algorithm analysis techniques such as amortized analysis, randomized algorithms analysis, and average-case analysis.\n",
        "   - Discuss advanced data structures and their analysis, including self-balancing trees (e.g., AVL trees, Red-Black trees) and advanced hashing techniques.\n",
        "\n",
        "2. **Computational Complexity Theory**:\n",
        "   - Introduce fundamental concepts in computational complexity theory such as P vs. NP, NP-completeness, and polynomial-time hierarchy.\n",
        "   - Discuss common complexity classes and their relationships, including P, NP, PSPACE, and EXP.\n",
        "\n",
        "3. **Cryptography Algorithms**:\n",
        "   - Explore cryptographic algorithms for encryption, decryption, digital signatures, and key exchange, such as RSA, AES, ECC, and Diffie-Hellman.\n",
        "   - Discuss cryptographic protocols for secure communication, authentication, and integrity verification.\n",
        "\n",
        "4. **Data Structures for Big Data**:\n",
        "   - Cover data structures and algorithms optimized for big data processing, such as Bloom filters, HyperLogLog, and distributed hash tables (DHTs).\n",
        "   - Discuss techniques for parallel and distributed processing of large-scale datasets, including MapReduce and Spark.\n",
        "\n",
        "5. **Optimization Algorithms**:\n",
        "   - Introduce optimization algorithms for solving continuous and discrete optimization problems, such as gradient descent, simulated annealing, genetic algorithms, and ant colony optimization.\n",
        "   - Discuss applications of optimization algorithms in areas like operations research, engineering design, and machine learning.\n",
        "\n",
        "6. **Parallel Computing Models**:\n",
        "   - Explore parallel computing models and frameworks such as SIMD (Single Instruction, Multiple Data), MIMD (Multiple Instruction, Multiple Data), and GPU computing.\n",
        "   - Discuss programming models and libraries for parallel computing, including OpenMP, CUDA, and MPI.\n",
        "\n",
        "7. **Game Theory Algorithms**:\n",
        "   - Introduce algorithms and concepts from game theory, such as Nash equilibrium, zero-sum games, and cooperative games.\n",
        "   - Discuss applications of game theory in fields like economics, computer science, and political science.\n",
        "\n",
        "8. **Sparse Matrix Algorithms**:\n",
        "   - Cover algorithms and data structures optimized for sparse matrices, such as Compressed Sparse Row (CSR) and Compressed Sparse Column (CSC) formats.\n",
        "   - Discuss techniques for efficiently performing matrix operations on sparse matrices, including matrix-vector multiplication and matrix factorization.\n",
        "\n",
        "9. **Streaming Algorithms**:\n",
        "   - Explore algorithms designed for processing continuous data streams with limited memory and computational resources.\n",
        "   - Discuss streaming algorithms for tasks like approximate counting, frequency estimation, and heavy hitters identification.\n",
        "\n",
        "10. **Data Compression Algorithms**:\n",
        "    - Introduce compression algorithms and techniques for reducing the size of data, including lossless compression (e.g., Huffman coding, Lempel-Ziv-Welch) and lossy compression (e.g., JPEG, MP3).\n",
        "    - Discuss applications of data compression in storage, transmission, and multimedia processing.\n",
        "\n"
      ],
      "metadata": {
        "id": "GGhhvWFczSqx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Algorithm Analysis (Advanced)**:\n",
        "\n",
        "In advanced algorithm analysis, we delve into more sophisticated techniques for evaluating the performance and behavior of algorithms. This includes analyzing algorithms in various contexts such as amortized analysis, randomized algorithms analysis, and average-case analysis. Additionally, we explore advanced data structures and their analysis to understand their efficiency and behavior in different scenarios.\n",
        "\n",
        "**Amortized Analysis**: Amortized analysis provides a way to analyze the average time complexity of a sequence of operations, rather than individual operations. It is particularly useful for analyzing data structures with varying costs for different operations.\n",
        "\n",
        "**Randomized Algorithms Analysis**: Randomized algorithms use randomization to make decisions during their execution. Analyzing randomized algorithms involves studying their expected performance over all possible random choices.\n",
        "\n",
        "**Average-Case Analysis**: Average-case analysis evaluates the performance of an algorithm based on the average input distribution. It considers the expected behavior of the algorithm over a range of inputs, rather than focusing solely on the worst-case scenario.\n",
        "\n",
        "**Advanced Data Structures**: Advanced data structures offer efficient solutions to specific problems or enable efficient operations on data. Self-balancing trees such as AVL trees and Red-Black trees maintain balance during insertion and deletion operations, ensuring efficient search, insertion, and deletion times.\n",
        "\n",
        "**Advanced Hashing Techniques**: Advanced hashing techniques optimize hash functions and collision resolution strategies to improve the performance of hash tables. This includes techniques like cuckoo hashing, hopscotch hashing, and perfect hashing, which aim to minimize collisions and improve lookup times.\n",
        "\n",
        "**Code Example**:\n",
        "\n",
        "Below is a Python code example demonstrating the usage of an AVL tree, a self-balancing binary search tree:\n"
      ],
      "metadata": {
        "id": "M9P8lUyft-EC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TreeNode:\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "        self.height = 1\n",
        "\n",
        "class AVLTree:\n",
        "    def __init__(self):\n",
        "        self.root = None\n",
        "\n",
        "    def _height(self, node):\n",
        "        if not node:\n",
        "            return 0\n",
        "        return node.height\n",
        "\n",
        "    def _balance(self, node):\n",
        "        if not node:\n",
        "            return 0\n",
        "        return self._height(node.left) - self._height(node.right)\n",
        "\n",
        "    def _update_height(self, node):\n",
        "        if not node:\n",
        "            return\n",
        "        node.height = 1 + max(self._height(node.left), self._height(node.right))\n",
        "\n",
        "    def _rotate_right(self, y):\n",
        "        x = y.left\n",
        "        T2 = x.right\n",
        "\n",
        "        x.right = y\n",
        "        y.left = T2\n",
        "\n",
        "        self._update_height(y)\n",
        "        self._update_height(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def _rotate_left(self, x):\n",
        "        y = x.right\n",
        "        T2 = y.left\n",
        "\n",
        "        y.left = x\n",
        "        x.right = T2\n",
        "\n",
        "        self._update_height(x)\n",
        "        self._update_height(y)\n",
        "\n",
        "        return y\n",
        "\n",
        "    def insert(self, root, key):\n",
        "        if not root:\n",
        "            return TreeNode(key)\n",
        "        if key < root.key:\n",
        "            root.left = self.insert(root.left, key)\n",
        "        else:\n",
        "            root.right = self.insert(root.right, key)\n",
        "\n",
        "        self._update_height(root)\n",
        "\n",
        "        balance = self._balance(root)\n",
        "\n",
        "        if balance > 1 and key < root.left.key:\n",
        "            return self._rotate_right(root)\n",
        "\n",
        "        if balance < -1 and key > root.right.key:\n",
        "            return self._rotate_left(root)\n",
        "\n",
        "        if balance > 1 and key > root.left.key:\n",
        "            root.left = self._rotate_left(root.left)\n",
        "            return self._rotate_right(root)\n",
        "\n",
        "        if balance < -1 and key < root.right.key:\n",
        "            root.right = self._rotate_right(root.right)\n",
        "            return self._rotate_left(root)\n",
        "\n",
        "        return root\n",
        "\n",
        "    def inorder_traversal(self, root):\n",
        "        if not root:\n",
        "            return\n",
        "        self.inorder_traversal(root.left)\n",
        "        print(root.key, end=\" \")\n",
        "        self.inorder_traversal(root.right)\n",
        "\n",
        "# Example usage:\n",
        "avl_tree = AVLTree()\n",
        "keys = [9, 5, 10, 0, 6, 11, -1, 1, 2]\n",
        "for key in keys:\n",
        "    avl_tree.root = avl_tree.insert(avl_tree.root, key)\n",
        "\n",
        "print(\"Inorder traversal of AVL tree:\")\n",
        "avl_tree.inorder_traversal(avl_tree.root)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNNSgzh00Cyd",
        "outputId": "641f3636-08f0-4765-bdd3-073b9da90ad3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inorder traversal of AVL tree:\n",
            "-1 0 1 2 5 6 9 10 11 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this example, we define an AVL tree data structure and demonstrate its usage by inserting a list of keys into the tree. The AVL tree automatically balances itself after each insertion to maintain its height-balanced property, ensuring efficient search, insertion, and deletion operations."
      ],
      "metadata": {
        "id": "Nx04s9Ls0DFw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Computational Complexity Theory**:\n",
        "\n",
        "Computational Complexity Theory is a branch of theoretical computer science that studies the resources required to solve computational problems. It aims to classify problems based on their inherent difficulty and understand the relationships between different classes of problems.\n",
        "\n",
        "**Fundamental Concepts**:\n",
        "\n",
        "1. **P vs. NP**:\n",
        "   - P stands for \"polynomial time,\" referring to the class of decision problems that can be solved by a deterministic Turing machine in polynomial time.\n",
        "   - NP stands for \"nondeterministic polynomial time,\" referring to the class of decision problems for which a potential solution can be verified by a deterministic Turing machine in polynomial time.\n",
        "   - The P vs. NP problem asks whether every problem whose solution can be quickly verified (in polynomial time) can also be solved quickly (in polynomial time). It is one of the most famous open problems in computer science.\n",
        "\n",
        "2. **NP-Completeness**:\n",
        "   - A problem is NP-complete if it is in the class NP and every problem in NP can be reduced to it in polynomial time.\n",
        "   - NP-complete problems are considered among the hardest problems in NP, as solving one of them efficiently would imply that every problem in NP can be solved efficiently (i.e., P = NP).\n",
        "\n",
        "3. **Polynomial-Time Hierarchy (PH)**:\n",
        "   - The polynomial-time hierarchy is a hierarchy of complexity classes based on the concept of alternating quantifiers.\n",
        "   - It extends the classes P and NP to higher levels by introducing the classes Σp and Πp, which represent the existential and universal versions of NP, respectively.\n",
        "   - The polynomial-time hierarchy is believed to be infinite and captures the complexity of problems that can be solved with alternating quantifiers.\n",
        "\n",
        "**Common Complexity Classes**:\n",
        "\n",
        "1. **P (Polynomial Time)**:\n",
        "   - The class of decision problems that can be solved by a deterministic Turing machine in polynomial time.\n",
        "   - Example: Sorting a list of numbers can be solved in O(n log n) time using algorithms like merge sort or heap sort.\n",
        "\n",
        "2. **NP (Nondeterministic Polynomial Time)**:\n",
        "   - The class of decision problems for which a potential solution can be verified by a deterministic Turing machine in polynomial time.\n",
        "   - Example: The Boolean satisfiability problem (SAT), where given a Boolean formula, determining if there exists an assignment of truth values to variables that satisfies the formula.\n",
        "\n",
        "3. **PSPACE (Polynomial Space)**:\n",
        "   - The class of decision problems that can be solved by a deterministic Turing machine using polynomial space.\n",
        "   - Example: Determining the winner of a two-player game like chess or Go, where the state space is exponentially large but can be represented in polynomial space.\n",
        "\n",
        "4. **EXP (Exponential Time)**:\n",
        "   - The class of decision problems that can be solved by a deterministic Turing machine in exponential time.\n",
        "   - Example: Finding the optimal solution to the traveling salesman problem (TSP) by trying all possible permutations of cities, which requires exponential time.\n",
        "\n",
        "**Code Example**:\n",
        "\n",
        "Below is a Python code example demonstrating the concept of checking if a given problem is in P or NP:\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qkKoz1wI0H9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_in_p(problem):\n",
        "    # Check if the problem can be solved in polynomial time\n",
        "    return True  # Placeholder for actual implementation\n",
        "\n",
        "def is_in_np(problem):\n",
        "    # Check if the problem's solution can be verified in polynomial time\n",
        "    return True  # Placeholder for actual implementation\n",
        "\n",
        "# Example usage:\n",
        "problem = \"Boolean satisfiability\"\n",
        "if is_in_p(problem):\n",
        "    print(problem, \"is in P.\")\n",
        "if is_in_np(problem):\n",
        "    print(problem, \"is in NP.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxPe4LP90Uue",
        "outputId": "c923e270-b4f4-4caa-b667-5ee39709d75e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Boolean satisfiability is in P.\n",
            "Boolean satisfiability is in NP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example, `is_in_p` and `is_in_np` are placeholder functions. In practice, determining whether a problem belongs to P or NP involves analyzing its algorithmic complexity and the nature of its solutions."
      ],
      "metadata": {
        "id": "o7DEXO-D0bl5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cryptography Algorithms:\n",
        "\n",
        "Cryptography algorithms are essential for securing sensitive data, facilitating secure communication, and ensuring the integrity and authenticity of information in various applications. They involve techniques for encryption, decryption, digital signatures, and key exchange. Let's explore some commonly used cryptographic algorithms:\n",
        "\n",
        "1. **RSA (Rivest-Shamir-Adleman)**:\n",
        "   - RSA is a widely used asymmetric encryption algorithm based on the difficulty of factoring large prime numbers.\n",
        "   - It involves generating a public-private key pair, where the public key is used for encryption and the private key is used for decryption.\n",
        "   - Example code:\n"
      ],
      "metadata": {
        "id": "c_OJDBNa0e4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycryptodome\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3-LhpyU3ZIZ",
        "outputId": "89a5e33f-f98a-46b2-91b9-d83eb9ac63b9"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycryptodome\n",
            "Successfully installed pycryptodome-3.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Crypto.PublicKey import RSA\n",
        "from Crypto.Cipher import PKCS1_OAEP\n",
        "\n",
        "# Generate key pair\n",
        "key = RSA.generate(2048)\n",
        "\n",
        "# Encrypt message using public key\n",
        "public_key = key.publickey()\n",
        "cipher = PKCS1_OAEP.new(public_key)\n",
        "encrypted_message = cipher.encrypt(b'Hello, World!')\n",
        "\n",
        "# Decrypt message using private key\n",
        "cipher = PKCS1_OAEP.new(key)\n",
        "decrypted_message = cipher.decrypt(encrypted_message)\n",
        "print(decrypted_message.decode())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4kt4pTe0yVN",
        "outputId": "65a9f283-1119-446b-ee48-886d71e1c6ca"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. **AES (Advanced Encryption Standard)**:\n",
        "   - AES is a symmetric encryption algorithm widely used for securing data at rest and in transit.\n",
        "   - It operates on fixed-size blocks of data and supports key lengths of 128, 192, or 256 bits.\n",
        "   - Example code:"
      ],
      "metadata": {
        "id": "nA4nTYPw1McS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Crypto.Cipher import AES\n",
        "from Crypto.Random import get_random_bytes\n",
        "from Crypto.Util.Padding import pad, unpad\n",
        "\n",
        "# Generate random key and IV\n",
        "key = get_random_bytes(16)\n",
        "iv = get_random_bytes(16)\n",
        "\n",
        "# Encrypt message\n",
        "cipher = AES.new(key, AES.MODE_CBC, iv)\n",
        "padded_message = pad(b'Hello, World!', AES.block_size)\n",
        "encrypted_message = cipher.encrypt(padded_message)\n",
        "\n",
        "# Decrypt message\n",
        "cipher = AES.new(key, AES.MODE_CBC, iv)\n",
        "decrypted_message = cipher.decrypt(encrypted_message)\n",
        "unpadded_message = unpad(decrypted_message, AES.block_size)\n",
        "print(unpadded_message.decode())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nRKyD1e1NQs",
        "outputId": "9e8d30db-a6d5-4e8b-ae29-e5a2e0831419"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, World!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **ECC (Elliptic Curve Cryptography)**:\n",
        "   - ECC is an asymmetric encryption algorithm based on the mathematical properties of elliptic curves.\n",
        "   - It provides strong security with smaller key sizes compared to RSA, making it suitable for resource-constrained environments.\n",
        "   - Example code:"
      ],
      "metadata": {
        "id": "tMxUA4Bb08Js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tinyec\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqQssjyy4OiF",
        "outputId": "69f41e11-0760-4887-8b6d-b1b25c5027fa"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tinyec\n",
            "  Downloading tinyec-0.4.0.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tinyec\n",
            "  Building wheel for tinyec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinyec: filename=tinyec-0.4.0-py3-none-any.whl size=20877 sha256=42416b5965ae490b7a507ead27f1a29b0e4385a1938f1fbb8d2faaea8c16aec9\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/37/a5/aa011cfa66451de6aa2dbccaa3e7862e8290f0946653753265\n",
            "Successfully built tinyec\n",
            "Installing collected packages: tinyec\n",
            "Successfully installed tinyec-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tinyec import registry\n",
        "\n",
        "# Generate curve and key pair\n",
        "curve = registry.get_curve('secp256r1')\n",
        "private_key = curve.field.random()\n",
        "public_key = private_key * curve.g\n",
        "\n",
        "# Encrypt message using public key\n",
        "message = b'Hello, World!'\n",
        "encrypted_message = public_key * message\n",
        "\n",
        "# Decrypt message using private key\n",
        "decrypted_message = private_key * encrypted_message\n",
        "print(decrypted_message)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "UGKd5p1O1dpC",
        "outputId": "2fbd3602-31ed-4326-961c-a1d2270f691f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'SubGroup' object has no attribute 'random'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-68d7f223d3dd>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Generate curve and key pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcurve\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'secp256r1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprivate_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpublic_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprivate_key\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcurve\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SubGroup' object has no attribute 'random'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "4. **Diffie-Hellman Key Exchange**:\n",
        "   - Diffie-Hellman is a key exchange algorithm that allows two parties to establish a shared secret over an insecure channel.\n",
        "   - It enables secure communication by allowing the parties to negotiate a shared secret without transmitting it over the channel.\n",
        "   - Example code:"
      ],
      "metadata": {
        "id": "lAQGpHQz02XN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cryptography.hazmat.primitives.asymmetric import dh\n",
        "from cryptography.hazmat.primitives import serialization\n",
        "\n",
        "# Generate private and public keys\n",
        "parameters = dh.generate_parameters(generator=2, key_size=2048)\n",
        "private_key = parameters.generate_private_key()\n",
        "public_key = private_key.public_key()\n",
        "\n",
        "# Serialize public key for transmission\n",
        "public_key_bytes = public_key.public_bytes(\n",
        "    encoding=serialization.Encoding.PEM,\n",
        "    format=serialization.PublicFormat.SubjectPublicKeyInfo\n",
        ")\n",
        "\n",
        "# Deserialize public key and perform key exchange\n",
        "peer_public_key = serialization.load_pem_public_key(public_key_bytes)\n",
        "shared_key = private_key.exchange(peer_public_key)\n"
      ],
      "metadata": {
        "id": "hA_WKwhw1t0U"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "These examples illustrate how cryptographic algorithms are used for encryption, decryption, key exchange, and securing communication in various applications. It's important to use these algorithms correctly and follow best practices to ensure the security of sensitive data and systems."
      ],
      "metadata": {
        "id": "Vi5LPehW1uJm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Structures for Big Data:**\n",
        "\n",
        "In the realm of big data processing, traditional data structures may not suffice due to the massive scale of the datasets involved. Specialized data structures and algorithms are required to efficiently handle and process these large volumes of data. Here, we'll discuss three such data structures optimized for big data processing: Bloom filters, HyperLogLog, and distributed hash tables (DHTs).\n",
        "\n",
        "1. **Bloom Filters**:\n",
        "   - Bloom filters are probabilistic data structures used to test whether an element is a member of a set. They offer a space-efficient solution for set membership queries with a small probability of false positives.\n",
        "   - Bloom filters use a bit array and multiple hash functions to represent the set. When an element is inserted, its hash values are used to set corresponding bits in the array.\n",
        "   - Membership queries involve hashing the element and checking if all corresponding bits are set in the array. False positives may occur, but false negatives are not possible.\n",
        "   \n",
        "Example code for implementing a Bloom filter in Python using the `bitarray` library:\n",
        "\n"
      ],
      "metadata": {
        "id": "R04j06GPLSog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitarray\n",
        "!pip install mmh3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAWO9v7qOiiz",
        "outputId": "ed92e4ae-e24a-4c75-b4c9-c4a6615eb2ae"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bitarray in /usr/local/lib/python3.10/dist-packages (2.9.2)\n",
            "Collecting mmh3\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mmh3\n",
            "Successfully installed mmh3-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bitarray import bitarray\n",
        "import mmh3\n",
        "\n",
        "class BloomFilter:\n",
        "    def __init__(self, size, num_hashes):\n",
        "        self.size = size\n",
        "        self.num_hashes = num_hashes\n",
        "        self.bit_array = bitarray(size)\n",
        "        self.bit_array.setall(0)\n",
        "\n",
        "    def add(self, item):\n",
        "        for i in range(self.num_hashes):\n",
        "            index = mmh3.hash(item, i) % self.size\n",
        "            self.bit_array[index] = 1\n",
        "\n",
        "    def __contains__(self, item):\n",
        "        for i in range(self.num_hashes):\n",
        "            index = mmh3.hash(item, i) % self.size\n",
        "            if not self.bit_array[index]:\n",
        "                return False\n",
        "        return True\n",
        "\n",
        "# Example usage:\n",
        "bloom_filter = BloomFilter(100, 3)\n",
        "bloom_filter.add(\"apple\")\n",
        "print(\"Is 'apple' in Bloom filter?\", \"apple\" in bloom_filter)  # Output: True\n",
        "print(\"Is 'banana' in Bloom filter?\", \"banana\" in bloom_filter)  # Output: False (may be a false positive)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3FQKCt5LuQw",
        "outputId": "8d496b3e-66a6-4c87-a74d-d47c76f94e04"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is 'apple' in Bloom filter? True\n",
            "Is 'banana' in Bloom filter? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **HyperLogLog (HLL)**:\n",
        "   - HyperLogLog is a probabilistic data structure used for estimating the cardinality of a multiset (the number of distinct elements in a set) with high accuracy and low memory usage.\n",
        "   - HLL achieves this by leveraging the properties of hash functions and probabilistic counting techniques. It approximates the number of unique elements by counting the number of leading zeros in the hash values of elements.\n",
        "   - HyperLogLog achieves high accuracy with relatively small memory requirements, making it suitable for large-scale data processing tasks where memory efficiency is crucial.\n",
        "\n",
        "Example code for implementing HyperLogLog in Python using the `hyperloglog` library:\n"
      ],
      "metadata": {
        "id": "2bmMyaYsLuhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hyperloglog\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gRxDBYUO9Iz",
        "outputId": "79a5e958-2c9b-41a1-afba-21c9812d19a6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hyperloglog\n",
            "  Downloading hyperloglog-0.0.14.tar.gz (36 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: hyperloglog\n",
            "  Building wheel for hyperloglog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hyperloglog: filename=hyperloglog-0.0.14-py3-none-any.whl size=37926 sha256=485611ab74b0f7203a2a82ca98573d69ae5a45df4f499a6520d917c299fed1f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/d9/23/3d8ebf80b75462b1c231ced0ae5834eb144e777a79db528289\n",
            "Successfully built hyperloglog\n",
            "Installing collected packages: hyperloglog\n",
            "Successfully installed hyperloglog-0.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hyperloglog\n",
        "\n",
        "# Create a HyperLogLog instance\n",
        "hll = hyperloglog.HyperLogLog(0.01)  # Desired error rate: 1%\n",
        "# Add elements to the HLL instance\n",
        "hll.add(\"apple\")\n",
        "hll.add(\"banana\")\n",
        "hll.add(\"orange\")\n",
        "# Estimate cardinality\n",
        "estimated_cardinality = len(hll)\n",
        "print(\"Estimated cardinality:\", estimated_cardinality)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esLTshnrMMgZ",
        "outputId": "f6a37152-d333-4b11-b21a-80dd1deb1a93"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated cardinality: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. **Distributed Hash Tables (DHTs)**:\n",
        "   - Distributed hash tables (DHTs) are decentralized distributed systems for storing and retrieving key-value pairs across a network of nodes.\n",
        "   - DHTs use consistent hashing to map keys to nodes in the network, ensuring that each key is stored at a predetermined location (node) in a balanced manner.\n",
        "   - They provide fault tolerance, scalability, and efficient lookup operations, making them suitable for building distributed systems and large-scale data storage solutions.\n",
        "\n",
        "Example code for implementing a simple DHT using the `hash_ring` library in Python:\n"
      ],
      "metadata": {
        "id": "G5Z3iSZcMNrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hash_ring\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-u_D2cQPI_0",
        "outputId": "1c3e9f16-20ce-41fb-d852-589618d006f9"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hash_ring\n",
            "  Downloading hash_ring-1.3.1.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: hash_ring\n",
            "  Building wheel for hash_ring (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hash_ring: filename=hash_ring-1.3.1-py3-none-any.whl size=4694 sha256=32a6d1daab32657207ef85c8954ce2f772cef5ece03fd871420a2387194d60ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/d1/e4/c940221ea198a90b615b87583bc08099a3c60c6091a55f9673\n",
            "Successfully built hash_ring\n",
            "Installing collected packages: hash_ring\n",
            "Successfully installed hash_ring-1.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from hashlib import md5\n",
        "except ImportError as e:\n",
        "    from md5 import md5\n",
        "\n",
        "class HashRing(object):\n",
        "    def __init__(self, nodes=None, replicas=100):\n",
        "        self.replicas = replicas\n",
        "        self.ring = dict()\n",
        "        self._sorted_keys = []\n",
        "\n",
        "        if nodes:\n",
        "            for node in nodes:\n",
        "                self.add_node(node)\n",
        "\n",
        "    def add_node(self, node):\n",
        "        for i in range(0, self.replicas):\n",
        "            key = self.gen_key('%s:%s' % (node, i))\n",
        "            self.ring[key] = node\n",
        "            self._sorted_keys.append(key)\n",
        "\n",
        "        self._sorted_keys.sort()\n",
        "\n",
        "    def remove_node(self, node):\n",
        "        for i in range(0, self.replicas):\n",
        "            key = self.gen_key('%s:%s' % (node, i))\n",
        "            del self.ring[key]\n",
        "            self._sorted_keys.remove(key)\n",
        "\n",
        "    def get_node(self, string_key):\n",
        "        return self.get_node_pos(string_key)[0]\n",
        "\n",
        "    def get_node_pos(self, string_key):\n",
        "        if not self.ring:\n",
        "            return None, None\n",
        "\n",
        "        key = self.gen_key(string_key)\n",
        "\n",
        "        nodes = self._sorted_keys\n",
        "        for i in range(len(nodes)):\n",
        "            node = nodes[i]\n",
        "            if key <= node:\n",
        "                return self.ring[node], i\n",
        "\n",
        "        return self.ring[nodes[0]], 0\n",
        "\n",
        "    def gen_key(self, key):\n",
        "        m = md5()\n",
        "        m.update(key.encode())\n",
        "        return m.hexdigest()\n"
      ],
      "metadata": {
        "id": "DqG8L4b-MYbO"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Techniques for Parallel and Distributed Processing:**\n",
        "\n",
        "Parallel and distributed processing of large-scale datasets is essential for achieving scalability and performance in big data analytics. Two commonly used techniques for parallel and distributed processing are MapReduce and Spark:\n",
        "\n",
        "1. **MapReduce**:\n",
        "   - MapReduce is a programming model and processing framework designed for parallel processing of large datasets across a cluster of commodity hardware.\n",
        "   - It consists of two main phases: the Map phase, where data is processed in parallel across multiple nodes, and the Reduce phase, where the results from the Map phase are aggregated and combined.\n",
        "   - MapReduce is fault-tolerant and scalable, making it suitable for processing large volumes of data in distributed environments.\n",
        "\n",
        "Example of a simple word count program using MapReduce:\n"
      ],
      "metadata": {
        "id": "BS4-Z2OoNpGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mrjob\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqBi32kUPyCG",
        "outputId": "532611fe-112c-488e-97b1-e146b0a6c60e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mrjob\n",
            "  Downloading mrjob-0.7.4-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.6/439.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from mrjob) (6.0.1)\n",
            "Installing collected packages: mrjob\n",
            "Successfully installed mrjob-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "from io import StringIO\n",
        "\n",
        "class MRWordCount(MRJob):\n",
        "    def mapper(self, _, line):\n",
        "        for word in line.split():\n",
        "            yield word, 1\n",
        "\n",
        "    def reducer(self, word, counts):\n",
        "        yield word, sum(counts)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_data = [\"Hello world\", \"Hello again\", \"Goodbye world\"]\n",
        "    mr_job = MRWordCount(args=input_data)\n",
        "    process = subprocess.Popen([\"python\", \"-m\", \"mrjob.job\", \"--no-conf\", \"-\"], stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    stdout, stderr = process.communicate(input=\"\\n\".join(input_data).encode())\n",
        "    output = StringIO(stdout.decode())\n",
        "    for line in output:\n",
        "        print(line.strip())\n",
        "\n"
      ],
      "metadata": {
        "id": "vvN0aRO8OD2_"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. **Apache Spark**:\n",
        "   - Apache Spark is an open-source distributed computing framework that provides an advanced execution engine for processing large-scale data sets.\n",
        "   - Spark offers a rich set of high-level APIs in programming languages like Python, Java, and Scala, including support for SQL queries, machine learning, and graph processing.\n",
        "   - It provides in-memory processing capabilities, fault tolerance, and efficient data caching, making it suitable for iterative and interactive data analysis tasks.\n",
        "\n",
        "Example of word count using Apache Spark's RDD API in Python:\n"
      ],
      "metadata": {
        "id": "XYxRH-hUMYwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaY0ieX-Q2wS",
        "outputId": "84421870-5dab-4c3b-dc75-e4a0cb43f96c"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=cca747f885845adea1bd018f09dc5afe03ac00b879041ee47ea9c3a510af10f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext\n",
        "\n",
        "# Create a SparkContext\n",
        "sc = SparkContext(\"local\", \"WordCount\")\n",
        "\n",
        "# Create an RDD from input data\n",
        "input_data = [\"Hello world\", \"Hello again\", \"Goodbye world\"]\n",
        "lines = sc.parallelize(input_data)\n",
        "\n",
        "# Perform word count using flatMap and reduceByKey transformations\n",
        "word_counts = lines.flatMap(lambda line: line.split()) \\\n",
        "                   .map(lambda word: (word, 1)) \\\n",
        "                   .reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "# Collect and print results\n",
        "for word, count in word_counts.collect():\n",
        "    print(word, count)\n",
        "\n",
        "# Stop the SparkContext\n",
        "sc.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au9qdk7aNGS5",
        "outputId": "ab8de82e-6ef5-4d93-a100-33f17dddf57b"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello 2\n",
            "world 2\n",
            "again 1\n",
            "Goodbye 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "These examples illustrate how data structures such as Bloom filters, HyperLogLog, and distributed hash tables (DHTs) can be used in big data processing scenarios, along with techniques like MapReduce and Spark for parallel and distributed processing of large-scale datasets."
      ],
      "metadata": {
        "id": "zMpgefXINGwO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimization Algorithms**:\n",
        "\n",
        "Optimization algorithms are methods used to find the best solution to a problem from a set of feasible solutions. These solutions can be continuous or discrete, and optimization algorithms aim to minimize or maximize an objective function while satisfying any constraints.\n",
        "\n",
        "Here's a brief explanation of some common optimization algorithms along with a code example for gradient descent:\n",
        "\n",
        "1. **Gradient Descent**:\n",
        "   - Gradient descent is a first-order iterative optimization algorithm for finding the minimum of a function. It iteratively moves in the direction opposite to the gradient of the function at the current point.\n",
        "   - It's widely used in machine learning for training models by minimizing the loss function.\n",
        "   - Example: Minimize the function \\( f(x) = x^2 \\) using gradient descent.\n"
      ],
      "metadata": {
        "id": "BEbHvpdISrJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(learning_rate, precision):\n",
        "    current_x = 6  # Initial guess\n",
        "    previous_step_size = 1\n",
        "    max_iterations = 1000\n",
        "    iterations = 0\n",
        "\n",
        "    df = lambda x: 2 * x  # Derivative of the function f(x) = x^2\n",
        "\n",
        "    while previous_step_size > precision and iterations < max_iterations:\n",
        "        previous_x = current_x\n",
        "        current_x = current_x - learning_rate * df(previous_x)\n",
        "        previous_step_size = abs(current_x - previous_x)\n",
        "        iterations += 1\n",
        "\n",
        "    print(\"The local minimum occurs at:\", current_x)\n",
        "\n",
        "# Example usage:\n",
        "learning_rate = 0.01\n",
        "precision = 0.0001\n",
        "gradient_descent(learning_rate, precision)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3_s_1bYTBpR",
        "outputId": "e52e4ae6-7020-4401-aafe-516599f51693"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The local minimum occurs at: 0.004894743001922687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This code performs gradient descent to find the minimum of the function \\( f(x) = x^2 \\) by iteratively updating the value of \\( x \\) until convergence.\n",
        "\n",
        "Other optimization algorithms like simulated annealing, genetic algorithms, and ant colony optimization have their own unique approaches to solving optimization problems and are applicable in various domains such as operations research, engineering design, and machine learning. Each algorithm has its strengths and weaknesses, making them suitable for different types of problems and scenarios."
      ],
      "metadata": {
        "id": "YE5kGWwITB54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parallel Computing Models**\n",
        "\n",
        "Parallel computing models allow for the concurrent execution of tasks, enabling faster processing and increased throughput compared to sequential processing. Three common parallel computing models are SIMD (Single Instruction, Multiple Data), MIMD (Multiple Instruction, Multiple Data), and GPU computing.\n",
        "\n",
        "1. **SIMD (Single Instruction, Multiple Data)**:\n",
        "   - In SIMD, the same instruction is executed simultaneously on multiple data points.\n",
        "   - SIMD architectures typically include vector processors, which operate on vectors or arrays of data elements in parallel.\n",
        "   - This model is suitable for tasks with data-level parallelism, such as multimedia processing and scientific computing.\n"
      ],
      "metadata": {
        "id": "-MtWZ-b_TFBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of SIMD using NumPy\n",
        "import numpy as np\n",
        "\n",
        "# Vectorized addition using SIMD\n",
        "def vector_addition(a, b):\n",
        "    return np.add(a, b)\n",
        "\n",
        "# Example usage\n",
        "a = np.array([1, 2, 3, 4])\n",
        "b = np.array([5, 6, 7, 8])\n",
        "result = vector_addition(a, b)\n",
        "print(\"Result of vector addition:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNm26LDYViaH",
        "outputId": "03d2d275-c67e-4615-a943-59ebb796edeb"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result of vector addition: [ 6  8 10 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. **MIMD (Multiple Instruction, Multiple Data)**:\n",
        "   - In MIMD, multiple processors execute different instructions on different sets of data independently.\n",
        "   - MIMD systems can have homogeneous or heterogeneous processors and can be distributed across multiple nodes in a network.\n",
        "   - This model is suitable for tasks with task-level or fine-grained parallelism, such as distributed computing and multiprocessing.\n"
      ],
      "metadata": {
        "id": "5Ut7VA4lVi_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of MIMD using Python multiprocessing\n",
        "from multiprocessing import Process\n",
        "\n",
        "# Function for parallel execution\n",
        "def square_numbers(numbers):\n",
        "    for i, num in enumerate(numbers):\n",
        "        numbers[i] = num * num\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    numbers = [1, 2, 3, 4, 5]\n",
        "    processes = []\n",
        "    for _ in range(2):  # Number of processes\n",
        "        p = Process(target=square_numbers, args=(numbers,))\n",
        "        processes.append(p)\n",
        "        p.start()\n",
        "    for p in processes:\n",
        "        p.join()\n",
        "    print(\"Squared numbers:\", numbers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQxEt5bQV14A",
        "outputId": "c1ca6892-82eb-4998-fbf2-fd33f0a697fa"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Squared numbers: [1, 2, 3, 4, 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. **GPU Computing**:\n",
        "   - GPU (Graphics Processing Unit) computing utilizes the parallel processing power of GPUs to accelerate general-purpose computing tasks.\n",
        "   - GPUs have thousands of cores optimized for parallel computation, making them well-suited for highly parallelizable tasks.\n",
        "   - CUDA (Compute Unified Device Architecture) is a popular parallel computing platform and programming model developed by NVIDIA for GPU programming.\n"
      ],
      "metadata": {
        "id": "8gMQ-nRiV2dR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9udj60BHWfLW",
        "outputId": "9fed272f-0ce9-49b4-9803-335553eb075c"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.tar.gz (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2024.1.1-py2.py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.2-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.10.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.5)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1-cp310-cp310-linux_x86_64.whl size=661204 sha256=9325f29188598f1f252fb95dc9cacce30f829e34829191b3366cc3ded35348eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/34/d2/9a349255a4eca3a486d82c79d21e138ce2ccd90f414d9d72b8\n",
            "Successfully built pycuda\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.3.2 pycuda-2024.1 pytools-2024.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# CUDA kernel for matrix multiplication\n",
        "matrix_mult_kernel = \"\"\"\n",
        "__global__ void matrix_multiply(float *a, float *b, float *c, int N) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        float sum = 0.0f;\n",
        "        for (int i = 0; i < N; ++i) {\n",
        "            sum += a[row * N + i] * b[i * N + col];\n",
        "        }\n",
        "        c[row * N + col] = sum;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "def matrix_multiply_gpu(a, b):\n",
        "    N = a.shape[0]\n",
        "    a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "    b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "    c_gpu = cuda.mem_alloc((N * N * np.dtype(np.float32).itemsize))\n",
        "\n",
        "    cuda.memcpy_htod(a_gpu, a)\n",
        "    cuda.memcpy_htod(b_gpu, b)\n",
        "\n",
        "    block_size = 16\n",
        "    grid_size = (N + block_size - 1) // block_size\n",
        "\n",
        "    mod = SourceModule(matrix_mult_kernel)\n",
        "    matrix_multiply = mod.get_function(\"matrix_multiply\")\n",
        "    matrix_multiply(a_gpu, b_gpu, c_gpu, np.int32(N), block=(block_size, block_size, 1), grid=(grid_size, grid_size))\n",
        "\n",
        "    result = np.empty_like(a)\n",
        "    cuda.memcpy_dtoh(result, c_gpu)\n",
        "    return result\n",
        "\n",
        "# Generate random matrices\n",
        "N = 64\n",
        "A = np.random.rand(N, N).astype(np.float32)\n",
        "B = np.random.rand(N, N).astype(np.float32)\n",
        "\n",
        "# Perform matrix multip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "N96sooNeV5If",
        "outputId": "af3a5a22-abd6-4a7d-bf36-6b02dc5530a0"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "libcuda.so.1: cannot open shared object file: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-7ff7048ed0b1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoinit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSourceModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pycuda/autoinit.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0matexit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Initialize CUDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pycuda/driver.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_driver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"_v2\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: libcuda.so.1: cannot open shared object file: No such file or directory",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "These examples illustrate the concepts of SIMD, MIMD, and GPU computing, along with code examples demonstrating their implementation using Python and relevant libraries/frameworks such as NumPy, multiprocessing, and PyCUDA. Each model offers different levels of parallelism and is suited for different types of parallel computing tasks."
      ],
      "metadata": {
        "id": "xsjGjvq0V7__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Game Theory Algorithms:**\n",
        "\n",
        "Game theory is a branch of mathematics and economics that deals with the analysis of strategic interactions between rational decision-makers. It provides a framework for understanding and predicting the behavior of individuals and groups in competitive situations. Game theory encompasses various algorithms and concepts, including Nash equilibrium, zero-sum games, and cooperative games.\n",
        "\n",
        "1. **Nash Equilibrium:**\n",
        "   - Nash equilibrium is a fundamental concept in game theory, referring to a situation where each player in a game makes the best decision possible given the decisions of the other players.\n",
        "   - In a Nash equilibrium, no player has an incentive to unilaterally deviate from their chosen strategy.\n",
        "   - The concept was introduced by John Nash and has applications in economics, biology, political science, and other fields.\n",
        "\n",
        "2. **Zero-Sum Games:**\n",
        "   - A zero-sum game is a type of game where the total payoff to all players remains constant, meaning that gains by one player are offset by losses by others.\n",
        "   - In zero-sum games, one player's gain is another player's loss, and the total sum of payoffs is zero.\n",
        "   - Examples of zero-sum games include poker, chess, and rock-paper-scissors.\n",
        "\n",
        "3. **Cooperative Games:**\n",
        "   - Cooperative games are games in which players can form coalitions or alliances to achieve mutual goals and share the resulting payoffs.\n",
        "   - Unlike zero-sum games, cooperative games allow for collaboration and joint decision-making among players.\n",
        "   - Cooperative game theory deals with concepts such as coalition formation, bargaining, and the distribution of surplus among coalition members.\n",
        "\n",
        "**Applications of Game Theory:**\n",
        "Game theory has numerous applications across various disciplines:\n",
        "\n",
        "- **Economics:** Game theory is extensively used in economics to model and analyze competitive markets, auctions, bargaining situations, and strategic interactions between firms and consumers.\n",
        "  \n",
        "- **Computer Science:** In computer science, game theory algorithms are applied in the design of algorithms for routing, network protocols, mechanism design, and artificial intelligence (AI) agents in games.\n",
        "  \n",
        "- **Political Science:** Game theory provides insights into political decision-making, voting behavior, international relations, conflict resolution, and negotiation strategies among nations and political entities.\n",
        "\n",
        "**Code Example - Nash Equilibrium:**\n",
        "\n",
        "Below is a Python code example demonstrating the computation of Nash equilibrium in a simple two-player game using the Nashpy library:\n",
        "\n"
      ],
      "metadata": {
        "id": "LZJUe86HWQPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nashpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ipmb_3ADni1",
        "outputId": "3abeb151-15ca-417f-a1ac-1d64ad92b818"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nashpy\n",
            "  Downloading nashpy-0.0.41-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from nashpy) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from nashpy) (1.11.4)\n",
            "Requirement already satisfied: networkx>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nashpy) (3.2.1)\n",
            "Collecting deprecated>=1.2.14 (from nashpy)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.14->nashpy) (1.14.1)\n",
            "Installing collected packages: deprecated, nashpy\n",
            "Successfully installed deprecated-1.2.14 nashpy-0.0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nashpy as nash\n",
        "\n",
        "# Define the payoff matrices for Player 1 and Player 2\n",
        "payoff_matrix_player1 = np.array([[2, 1], [0, 3]])\n",
        "payoff_matrix_player2 = np.array([[2, 0], [1, 3]])\n",
        "\n",
        "# Create the game instance\n",
        "game = nash.Game(payoff_matrix_player1, payoff_matrix_player2)\n",
        "\n",
        "# Compute the Nash equilibrium\n",
        "nash_eqs = game.support_enumeration()\n",
        "\n",
        "# Print the Nash equilibrium strategies and payoffs\n",
        "for eq in nash_eqs:\n",
        "    print(\"Nash Equilibrium Strategy (Player 1):\", eq[0])\n",
        "    print(\"Nash Equilibrium Strategy (Player 2):\", eq[1])\n",
        "    print(\"Payoffs:\", game[eq])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YxjNv_tDYTR",
        "outputId": "ff4205b8-858f-4552-a314-cc54669643bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nash Equilibrium Strategy (Player 1): [1. 0.]\n",
            "Nash Equilibrium Strategy (Player 2): [1. 0.]\n",
            "Payoffs: [2. 2.]\n",
            "Nash Equilibrium Strategy (Player 1): [0. 1.]\n",
            "Nash Equilibrium Strategy (Player 2): [0. 1.]\n",
            "Payoffs: [3. 3.]\n",
            "Nash Equilibrium Strategy (Player 1): [0.5 0.5]\n",
            "Nash Equilibrium Strategy (Player 2): [0.5 0.5]\n",
            "Payoffs: [1.5 1.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This code computes the Nash equilibrium strategies and corresponding payoffs for a simple two-player game represented by the given payoff matrices. It demonstrates how Nashpy library can be used to analyze strategic interactions and find equilibrium solutions in games."
      ],
      "metadata": {
        "id": "DDpfH3HlDZIs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sparse Matrix Algorithms:\n",
        "\n",
        "Sparse matrices are matrices where most of the elements are zero. Storing and operating on such matrices in their dense form can be highly inefficient in terms of memory and computational resources. Sparse matrix algorithms and data structures are designed to efficiently handle sparse matrices by only storing non-zero elements and their corresponding indices.\n",
        "\n",
        "### Compressed Sparse Row (CSR) and Compressed Sparse Column (CSC) formats:\n",
        "\n",
        "**Compressed Sparse Row (CSR)**:\n",
        "- In CSR format, the matrix is represented by three arrays: values, columns, and indptr.\n",
        "- The `values` array stores non-zero elements of the matrix in row-major order.\n",
        "- The `columns` array stores the column indices corresponding to the non-zero elements.\n",
        "- The `indptr` array stores the indices of the starting positions of rows in the `values` and `columns` arrays.\n",
        "\n",
        "**Compressed Sparse Column (CSC)**:\n",
        "- CSC format is similar to CSR format, but it stores the matrix in column-major order.\n",
        "- The `values` array stores non-zero elements of the matrix in column-major order.\n",
        "- The `rows` array stores the row indices corresponding to the non-zero elements.\n",
        "- The `indptr` array stores the indices of the starting positions of columns in the `values` and `rows` arrays.\n",
        "\n",
        "### Matrix Operations on Sparse Matrices:\n",
        "\n",
        "1. **Matrix-Vector Multiplication**:\n",
        "   - To perform matrix-vector multiplication efficiently, we iterate over non-zero elements of the matrix and update the corresponding elements of the resulting vector.\n",
        "   - This operation can be performed in linear time complexity proportional to the number of non-zero elements in the matrix.\n",
        "\n",
        "2. **Matrix Factorization**:\n",
        "   - Matrix factorization decomposes a sparse matrix into two or more matrices that represent its structure or properties.\n",
        "   - Common matrix factorization techniques include LU decomposition, QR decomposition, and Singular Value Decomposition (SVD).\n",
        "   - These factorizations can be used for tasks like solving linear systems, finding eigenvalues/eigenvectors, and dimensionality reduction.\n",
        "\n",
        "### Code Example:\n",
        "\n",
        "Here's a Python code example demonstrating the creation of a sparse matrix in CSR format and performing matrix-vector multiplication:\n"
      ],
      "metadata": {
        "id": "8Lkl4UFnD_KT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Create a sparse matrix in CSR format\n",
        "data = np.array([1, 2, 3, 4, 5, 6])\n",
        "rows = np.array([0, 0, 1, 1, 2, 2])\n",
        "columns = np.array([0, 2, 0, 1, 1, 2])\n",
        "sparse_matrix = csr_matrix((data, (rows, columns)), shape=(3, 3))\n",
        "\n",
        "# Define a vector for multiplication\n",
        "vector = np.array([1, 2, 3])\n",
        "\n",
        "# Perform matrix-vector multiplication\n",
        "result = sparse_matrix.dot(vector)\n",
        "\n",
        "print(\"Sparse Matrix (CSR format):\\n\", sparse_matrix.toarray())\n",
        "print(\"Vector:\\n\", vector)\n",
        "print(\"Result of Matrix-Vector Multiplication:\\n\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPjdHB81EMhy",
        "outputId": "a2d645db-287e-48af-c61f-56b27d5be77a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparse Matrix (CSR format):\n",
            " [[1 0 2]\n",
            " [3 4 0]\n",
            " [0 5 6]]\n",
            "Vector:\n",
            " [1 2 3]\n",
            "Result of Matrix-Vector Multiplication:\n",
            " [ 7 11 28]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This code creates a sparse matrix in CSR format, defines a vector, and then performs matrix-vector multiplication efficiently. Sparse matrices and their algorithms play a crucial role in various domains such as scientific computing, machine learning, and network analysis where large and sparse datasets are common."
      ],
      "metadata": {
        "id": "edT5gTGgEM4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Streaming Algorithms:\n",
        "\n",
        "Streaming algorithms are designed to process continuous data streams in real-time, where data arrives continuously and needs to be processed with limited memory and computational resources. These algorithms are particularly useful in scenarios where it's impractical or impossible to store the entire data stream due to its size or rate of arrival.\n",
        "\n",
        "Streaming algorithms aim to provide approximate solutions to various tasks such as approximate counting, frequency estimation, and identifying heavy hitters (elements with high frequencies) within the data stream. These tasks are crucial in various applications including network traffic monitoring, clickstream analysis, and monitoring sensor data in IoT (Internet of Things) devices.\n",
        "\n",
        "Here's a brief explanation of each task along with a code example:\n",
        "\n",
        "1. **Approximate Counting**:\n",
        "   Approximate counting aims to estimate the total number of distinct elements in a data stream. This task is essential when the size of the data stream is too large to store in memory, and we're interested in obtaining a quick estimate rather than an exact count.\n"
      ],
      "metadata": {
        "id": "BCDS_ccsEduj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def approximate_counting(stream):\n",
        "    counter = Counter()\n",
        "    for item in stream:\n",
        "        counter[item] += 1\n",
        "    return len(counter)\n",
        "\n",
        "# Example usage:\n",
        "stream = [1, 2, 3, 1, 4, 2, 5, 3, 6, 7, 8, 1]\n",
        "distinct_count = approximate_counting(stream)\n",
        "print(\"Approximate count:\", distinct_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXwnytD9Ey-r",
        "outputId": "e3e69d7f-f94a-4386-e880-5016cb78241f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approximate count: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "2. **Frequency Estimation**:\n",
        "   Frequency estimation involves approximating the frequency of elements in a data stream. Instead of storing the entire stream, streaming algorithms maintain summary data structures to estimate the frequency of each element.\n",
        "\n"
      ],
      "metadata": {
        "id": "xxabVoUWEzao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def frequency_estimation(stream):\n",
        "    counter = Counter()\n",
        "    for item in stream:\n",
        "        counter[item] += 1\n",
        "    return {key: value / len(stream) for key, value in counter.items()}\n",
        "\n",
        "# Example usage:\n",
        "stream = [1, 2, 3, 1, 4, 2, 5, 3, 6, 7, 8, 1]\n",
        "frequency_estimates = frequency_estimation(stream)\n",
        "print(\"Frequency estimates:\", frequency_estimates)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2yw6u66E0xw",
        "outputId": "0e1a9b1e-c21f-4989-d6a7-0dc5e07c604a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequency estimates: {1: 0.25, 2: 0.16666666666666666, 3: 0.16666666666666666, 4: 0.08333333333333333, 5: 0.08333333333333333, 6: 0.08333333333333333, 7: 0.08333333333333333, 8: 0.08333333333333333}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "3. **Heavy Hitters Identification**:\n",
        "   Heavy hitters identification involves identifying elements in the data stream with high frequencies, i.e., elements that appear significantly more frequently than others. This task is useful for detecting anomalies or popular items in the stream.\n"
      ],
      "metadata": {
        "id": "JjSwpSGdE1DM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def heavy_hitters(stream, threshold):\n",
        "    counter = Counter()\n",
        "    for item in stream:\n",
        "        counter[item] += 1\n",
        "    return {key: value for key, value in counter.items() if value >= threshold}\n",
        "\n",
        "# Example usage:\n",
        "stream = [1, 2, 3, 1, 4, 2, 5, 3, 6, 7, 8, 1]\n",
        "threshold = len(stream) // 4  # For demonstration, threshold set to 25% of stream size\n",
        "heavy_hitters = heavy_hitters(stream, threshold)\n",
        "print(\"Heavy hitters:\", heavy_hitters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYZpUnIvE3tO",
        "outputId": "32a2072b-8421-4da1-aab1-1721b741f66e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Heavy hitters: {1: 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These code examples demonstrate basic implementations of streaming algorithms for approximate counting, frequency estimation, and heavy hitters identification. Depending on the specific requirements and characteristics of the data stream, more sophisticated streaming algorithms and data structures may be employed to achieve better accuracy and efficiency."
      ],
      "metadata": {
        "id": "VmsPzJ1RE4En"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Compression Algorithms:**\n",
        "\n",
        "Data compression algorithms are techniques used to reduce the size of data, making it more efficient to store, transmit, and process. There are two main categories of data compression: lossless compression and lossy compression.\n",
        "\n",
        "1. **Lossless Compression**:\n",
        "   Lossless compression algorithms reduce the size of data without losing any information. Examples of lossless compression algorithms include Huffman coding and Lempel-Ziv-Welch (LZW) compression.\n",
        "\n",
        "   - **Huffman Coding**: Huffman coding is a variable-length prefix coding algorithm that assigns shorter codes to more frequent symbols and longer codes to less frequent symbols.\n",
        "   - **Lempel-Ziv-Welch (LZW)**: LZW is a dictionary-based compression algorithm that replaces repeated patterns of characters with shorter codes.\n",
        "\n",
        "2. **Lossy Compression**:\n",
        "   Lossy compression algorithms reduce the size of data by removing redundant or less important information. Lossy compression results in some loss of data fidelity, but it is often acceptable in scenarios where some loss of quality is tolerable.\n",
        "\n",
        "   - **JPEG (Joint Photographic Experts Group)**: JPEG is a widely used lossy compression algorithm for compressing images. It achieves compression by discarding high-frequency information that is less perceptible to the human eye.\n",
        "   - **MP3 (MPEG Audio Layer III)**: MP3 is a popular lossy compression algorithm used for compressing audio files. It achieves compression by removing frequencies that are less audible to humans.\n",
        "\n",
        "**Applications of Data Compression:**\n",
        "\n",
        "Data compression has various applications in different domains, including:\n",
        "\n",
        "- **Storage**: Compressed data requires less storage space, allowing for more efficient use of storage devices such as hard drives, solid-state drives (SSDs), and memory cards.\n",
        "- **Transmission**: Compressed data can be transmitted over networks more quickly and efficiently, reducing bandwidth usage and transmission times. This is particularly important for streaming media, file downloads, and communication systems.\n",
        "- **Multimedia Processing**: Data compression enables the storage and transmission of multimedia content such as images, audio, and video in a compressed format. This allows for the efficient distribution of multimedia content over the internet and other digital channels.\n",
        "\n",
        "**Code Example (Huffman Coding):**\n",
        "\n",
        "Below is a Python implementation of the Huffman coding algorithm:\n"
      ],
      "metadata": {
        "id": "bfRmem7iFgUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "class HuffmanNode:\n",
        "    def __init__(self, char, freq):\n",
        "        self.char = char\n",
        "        self.freq = freq\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self.freq < other.freq\n",
        "\n",
        "def build_huffman_tree(text):\n",
        "    frequency = Counter(text)\n",
        "    heap = [HuffmanNode(char, freq) for char, freq in frequency.items()]\n",
        "    heapq.heapify(heap)\n",
        "    while len(heap) > 1:\n",
        "        left = heapq.heappop(heap)\n",
        "        right = heapq.heappop(heap)\n",
        "        merged = HuffmanNode(None, left.freq + right.freq)\n",
        "        merged.left = left\n",
        "        merged.right = right\n",
        "        heapq.heappush(heap, merged)\n",
        "    return heap[0]\n",
        "\n",
        "def build_huffman_codes(root, code='', codes={}):\n",
        "    if root:\n",
        "        if not root.left and not root.right:\n",
        "            codes[root.char] = code\n",
        "        build_huffman_codes(root.left, code + '0', codes)\n",
        "        build_huffman_codes(root.right, code + '1', codes)\n",
        "    return codes\n",
        "\n",
        "def huffman_compress(text):\n",
        "    root = build_huffman_tree(text)\n",
        "    codes = build_huffman_codes(root)\n",
        "    compressed_text = ''.join(codes[char] for char in text)\n",
        "    return compressed_text, codes\n",
        "\n",
        "def huffman_decompress(compressed_text, codes):\n",
        "    reverse_codes = {code: char for char, code in codes.items()}\n",
        "    decoded_text = ''\n",
        "    code = ''\n",
        "    for bit in compressed_text:\n",
        "        code += bit\n",
        "        if code in reverse_codes:\n",
        "            decoded_text += reverse_codes[code]\n",
        "            code = ''\n",
        "    return decoded_text\n",
        "\n",
        "# Example usage:\n",
        "text = \"hello world\"\n",
        "compressed_text, codes = huffman_compress(text)\n",
        "print(\"Compressed Text:\", compressed_text)\n",
        "print(\"Huffman Codes:\", codes)\n",
        "decoded_text = huffman_decompress(compressed_text, codes)\n",
        "print(\"Decoded Text:\", decoded_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fNVxjlEFu9z",
        "outputId": "04506ed9-6103-4b65-f153-f6b09b6a66ac"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compressed Text: 11100001010110111101111001010001\n",
            "Huffman Codes: {'e': '000', 'd': '001', 'r': '010', 'w': '011', 'l': '10', 'o': '110', 'h': '1110', ' ': '1111'}\n",
            "Decoded Text: hello world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example demonstrates how Huffman coding can be used to compress and decompress text data. The compressed text and Huffman codes are generated using the `huffman_compress` function, and the original text is recovered using the `huffman_decompress` function."
      ],
      "metadata": {
        "id": "OIcv2au4FvUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! Here are some more topics, each of these topics offers opportunities for further exploration and understanding in the realm of algorithms, data structures, and their applications in various domains.\n",
        "\n",
        "11. **Probabilistic Data Structures**:\n",
        "    - Introduce data structures optimized for probabilistic operations and approximate queries, such as Bloom filters, Count-Min Sketch, and HyperLogLog.\n",
        "    - Discuss applications of probabilistic data structures in big data analytics, network monitoring, and database systems.\n",
        "\n",
        "12. **Online Algorithms**:\n",
        "    - Explore algorithms designed to make decisions in an online fashion, where input arrives incrementally and decisions must be made without knowledge of future inputs.\n",
        "    - Discuss online algorithms for tasks such as caching, task scheduling, and resource allocation.\n",
        "\n",
        "13. **Fault-Tolerant Algorithms**:\n",
        "    - Cover algorithms and techniques for designing fault-tolerant systems that can operate reliably in the presence of failures, faults, or errors.\n",
        "    - Discuss fault-tolerant consensus algorithms, replication strategies, and Byzantine fault tolerance.\n",
        "\n",
        "14. **Distributed Algorithms**:\n",
        "    - Introduce algorithms and protocols for distributed computing systems, including leader election, distributed consensus, and distributed transaction processing.\n",
        "    - Discuss challenges and solutions in designing scalable and fault-tolerant distributed algorithms.\n",
        "\n",
        "15. **Blockchain and Cryptocurrency**:\n",
        "    - Explore the underlying algorithms and concepts behind blockchain technology and cryptocurrencies like Bitcoin and Ethereum.\n",
        "    - Discuss consensus mechanisms (e.g., Proof of Work, Proof of Stake), smart contracts, and decentralized applications (DApps).\n",
        "\n",
        "16. **Graph Processing Systems**:\n",
        "    - Cover distributed graph processing frameworks and systems designed for analyzing large-scale graphs, such as Apache Giraph, Apache Flink, and Apache Spark GraphX.\n",
        "    - Discuss algorithms and optimizations for graph analytics tasks like graph traversal, community detection, and graph algorithms parallelization.\n",
        "\n",
        "17. **Quantum Algorithms (Advanced)**:\n",
        "    - Dive deeper into quantum algorithms beyond basic quantum computing concepts, including quantum Fourier transform, quantum phase estimation, and quantum teleportation.\n",
        "    - Discuss potential applications of quantum algorithms in cryptography, optimization, and machine learning.\n",
        "\n",
        "18. **Web Algorithms and Data Structures**:\n",
        "    - Explore algorithms and data structures optimized for web applications and services, including URL routing, caching strategies, and content delivery networks (CDNs).\n",
        "    - Discuss techniques for optimizing web performance, handling large-scale web traffic, and ensuring reliability and scalability.\n",
        "\n",
        "19. **Data Privacy and Security**:\n",
        "    - Introduce algorithms and techniques for preserving data privacy and security in applications dealing with sensitive or personal information.\n",
        "    - Discuss cryptographic primitives for secure communication, privacy-preserving data mining, and differential privacy.\n",
        "\n",
        "20. **Recommender Systems (Advanced)**:\n",
        "    - Dive deeper into advanced techniques for building recommender systems, such as collaborative filtering with matrix factorization, content-based filtering, and hybrid approaches.\n",
        "    - Discuss challenges and solutions in designing personalized and scalable recommender systems for various domains.\n",
        "\n"
      ],
      "metadata": {
        "id": "Zy5cEJm7F6X0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "f2O_Uk8OGY19"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}